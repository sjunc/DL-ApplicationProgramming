
# 딥러닝 응용 프로그래밍
----  
기본 개념 복습  
인공지능 EX.전문가 시스템  
  |  
머신러닝 EX.인공신경망(ANN), SVM, DecisionTree  
  |  
딥러닝 EX.CNN(Convolutional Neural Network, RNN(Recurrent Neural Network), RBM(Restricted Boltzmann Machine)    

## 2주차 인공지능(AI, Artificial Intelligence)  
 정의  
- 인간의 지능적인 작업을 컴퓨터 시스템이 수행하도록 하는 기술과 학문 분야  
- 문제 해결, 추론, 학습, 자연어 처리, 로봇 제어 등이 포함됨  
 예  
- 챗봇 (예: ChatGPT) - 자율 주행 자동차  
- 음성 인식 (예: STT(Speech-to-Text) 시스템)  
- 가상 비서(Virtual Assistant) (예: Siri, Google Assistant)
    
### 머신러닝(ML, Machine Learning)  
정의  
- 인공지능의 하위 분야로, 컴퓨터가 명시적으로 프로그래밍되지 않고도 데이터를 학습하여 예측하거나 결정을 내리는 기술   
- 지도학습, 비지도학습, 강화학습으로 구분됨   
예  
- 이메일 스팸 필터링 (스팸/정상 메일 분류) classfication  
- 추천 시스템 (예: 넷플릭스 영화 추천)  
- 질병 진단 모델 (의료 데이터 분석)  
    
=컴퓨터가 학습할 수 있게 하는 알고리즘과 기술을 개발하는 분야  
  
• 머신 러닝 학습 과정  
• 머신 러닝은 학습 단계(learning)와 예측 단계(prediction)로 이루어짐  
• 학습 단계에서는 학습 데이터를 대상으로 머신 러닝 알고리즘을 적용하여 학습시키고, 이 학습 결과로 모형(model)이 생성됨  
• 예측 단계에서는 학습 단계에서 생성된 모형에 새로운 데이터를 적용하여 결과를 예측함  
   
과정   
특성 추출, 특징 추출(feature extraction)   
• 컴퓨터가 입력받은 데이터를 분석하여 일정한 패턴이나 규칙을 찾아 내려면 사람이 인지하는 데이터를 컴퓨터가 인지할 수 있는 데이터로 변환해 주어야 함  
• 이때 데이터별로 어떤 특징을 가지고 있는지 찾아내고, 그것을 토대로 데이터를 벡터로 변환하는 작업을 특성 추출이라고 함   
  
머신 러닝의 주요 구성 요소는 데이터와 모델(모형)   
데이터(자료)는 머신 러닝이 학습 모델을 만드는 데 사용하는 것  
편향되지 않는 훈련 데이터를 확보하는 것이 중요함  
또한, 학습에 필요한 데이터가 수집되었다면 훈련을 위해 ‘훈련 데이터셋’과 ‘검증 데이터셋’ 용도로 분리해서 사용  
보통 데이터의 80%는 훈련용으로, 20%는 검증용으로 분리해서 사용  

모델(model)은 머신 러닝의 학습 단계에서 얻은 최종 결과물로 가설이라고도 함  
• 예를 들어 “입력 데이터의 패턴은 A와 같다.”라는 가정을 머신 러닝에서는 모델이라고 함  
• 모델의 학습 절차는 다음과 같음  
1. 모델(또는 가설) 선택    
2. 모델 학습 및 평가   
3. 평가를 바탕으로 모델 업데이트(개선)  
    
• 이 세 단계를 반복하면서 주어진 문제를 가장 잘 풀 수 있는 모델을 찾음  
  
머신러닝 지도학습 / 비지도 학습 / 강화 학습 ->  
### 딥러닝(DL, Deep Learning)   
정의  
- 머신러닝의 하위 분야로, 인간의 뇌 신경망을 모방한 인공신경망(ANN)을 사용하여 데이터를 학습하는 기술  
- 다층 신경망(Deep Neural Network)을 활용하여 복잡한 패턴을 분석하고 처리  
예
- 이미지 인식(얼굴 인식, 자율 주행 자동차의 카메라)  
- 자연어 처리(번역, 감정 분석, 챗봇)   
- 음성 합성 (TTS, 딥페이크 음성)    

딥러닝은 인간의 신경망 원리를 모방한 심층 신경망(Multi Layer) 이론을 기반으로 고안된 머신 러닝 방법의 일종  
• 인간의 뇌가 많은 수의 뉴런(neuron)과 시냅스(synapse)로 구성되어 있는 것에 착안하여 컴퓨터에 뉴런과 시냅스 개념을 적용함  
• 각각의 뉴런은 복잡하게 연결된 수많은 뉴런을 병렬 연산하여 기존에 컴퓨터가 수행하지 못했던 음성·영상 인식 등의 처리를 가능하게 함  

인간의 뉴런 구조  
수상돌기: 주변이나 다른 뉴런에서 자극을 받아들이고, 이 자극들을 전기적 신호 형태로 세포체와 축색돌기로 보내는 역할을 함  
시냅스: 신경 세포들이 이루는 연결 부위로, 한 뉴런의 축색돌기와 다음 뉴런의 수상돌기가 만나는 부분  
축삭돌기: 다른 뉴런(수상돌기)에 신호를 전달하는 기능을 하는 뉴런의 한 부분  
- 뉴런에서 뻗어 있는 돌기 중 가장 길며, 단 한 개만 있음  
축삭말단: 전달된 전기 신호를 받아 신경 전달 물질을 시냅스 틈새로 분비  
  
이걸 본 따 퍼셉트론으로 만듬  
   
1. 데이터 준비: 딥러닝을 통해 구현하고자 하는 기능에 필요한 데이터들을 수집하고 전처리함.  
2. 모델 정의: 모델 정의 단계에서 모델의 구조를 결정하고, 신경망을 생성함.  
일반적으로 은닉층 개수가 많을수록(깊을수록) 성능이 좋아지지만 과적합이 발생할 확률이 높음  
3. 모델 컴파일: 컴파일 단계에서 활성화 함수, 손실 함수, 옵티마이저를 선택  
훈련 데이터셋 형태가 연속형이라면 평균 제곱 오차(Mean Squared Error, MSE)를 사용할 수 있으며, 이진 분류(binary classification)라면 크로스 엔트로피(cross-entropy)를 선택할 수 있음   
4. 모델 훈련: 훈련 단계에서는 한 번에 처리할 데이터양을 적절하게 지정함   
전체 훈련 데이터셋에서 일정한 묶음으로 나누어 처리할 수 있는 배치(Batch)와 훈련의 횟수인 에폭(Epoch) 선택이 중요함.  
이때 파라미터와 하이퍼파라미터에 대한 최적의 값을 찾을 수 있어야 함  
5. 모델 평가: 검증 데이터셋을 생성한 모델에 적용하여 실제로 예측을 진행해보는 단계.  
성능이 낮다면 파라미터를 튜닝하거나, 신경망 자체를 재설계할 수 있음

ex. 훈련 데이터셋 1000개 있음.   
batch size 20, epoch 10번임.  
한번 훈련데이터 전체를 볼 때까지 가중치가 업데이터가 50번 총 500번의 가중치 변경이 일어남.  iteration  
  
딥러닝 학습 과정에서 중요한 핵심 구성 요소는 신경망과 역전파  
딥러닝은 머신 러닝의 한 분야이기는 하지만, 심층 신경망(deep neural network)을 가지고 있다는 점에서 머신 러닝과 차이가 있음  
심층 신경망에는 데이터셋의 어떤 특성들이 중요한지 스스로에게 가르쳐 줄 수 있는 기능이 있음  

|특징 | 머신러닝 | 딥러닝 | 
|------|---|------|
|데이터 요구량| 적은 데이터로도 가능 | 대량의 데이터 필요 (수십만~수백만 개)|
|특징 추출 | 사람이 직접 특징을 설계 | 모델이 스스로 특징을 추출|
|필요 연산량 | 비교적 낮음 (CPU 가능) | 높음 (GPU/TPU 연산 필요)|
|모델 해석 가능성 | 해석 가능 (규칙 기반 예측) | 해석이 어려움 (블랙박스)| 
|학습 속도 | 상대적으로 빠름 (수분~수시간) | 느림 ( 수십 ~ 수백만 개 데이터, 몇 시간 ~ 며칠 )|
|적용 사례 | 의사 결정 트리, 랜덤 포레스트,SVM, K-NN, 선형 회귀 | CNN (이미지 인식), RNN (자연어 처리),GAN (이미지 생성),트랜스포머 (ChatGPT, BERT)|  
  
GPT (Generative Pretrained Transformer)  

### 지도학습 / 비지도학습 / 강화학습   
지도학습 : 입력 데이터 X -> 정답 데이터 Y   
정의  
입력 데이터(X)와 그에 대응하는 정답 데이터(Y, 레이블)가 함께 제공되는 학습방식   
- 모델은 이러한 데이터를 학습하여 새로운 입력에 대한 정확한 출력을 예측함   
 주요 기법  
- 분류(Classification): 데이터를 미리 정의된 카테고리로 분류함(환자인지, 강아지/고양이/스팸판별)  
- 회귀(Regression): 연속적인 값을 예측함(공부시간 별 성적)  
예  
- 이메일 스팸 필터링: 이메일의 내용이나 메타데이터를 기반으로 스팸 여부를 분류함   
- 손글씨 숫자 인식: 이미지에서 손으로 쓴 숫자를 인식하여 디지털 형식으로 변환함   
- 주택 가격 예측: 주택의 면적, 위치, 방 수 등의 특성을 기반으로 가격을 예측함   
- 음성 인식: 음성 데이터를 텍스트로 변환함   
   
비지도학습    
정의  
- 정답 데이터(레이블) 없이 입력 데이터(X)만으로 학습하는 방식  
- 데이터의 숨겨진 구조나 패턴을 발견하는 데 중점을 둠   
주요 기법  
- 군집화(Clustering): 유사한 특성을 가진 데이터들을 그룹으로 묶음  
- 차원 축소(Dimensionality Reduction): 고차원 데이터를 저차원으로 축소하여 주요 특징을 추출함.(PCA)    
예  
- 고객 세분화: 고객의 구매 행동이나 특성을 기반으로 유사한 그룹으로 분류함  
- 이상 탐지: 정상 패턴에서 벗어난 데이터를 탐지하여 이상 여부를 판단함   
   
강화학습
정의  
에이전트(Agent)가 환경(Environment)과 상호작용하며 보상(Reward)을 최대화하는 행동 전략을 학습하는 방식  
- 에이전트는 행동에 따른 보상을 통해 최적의 정책을 학습함(장기적인 보상을 고려해야 함)  
 주요 개념  
- 에이전트(Agent): 행동을 수행하는 주체  
- 환경(Environment): 에이전트가 상호작용하는 대상  
- 상태(State): 현재 환경의 상황  
- 행동(Action): 에이전트가 취할 수 있는 선택지  
- 보상(Reward): 행동의 결과로 얻는 피드백  
 예  
- 게임 AI: 체스, 바둑 등에서 최적의 수를 두기 위해 학습함  
- 로봇 제어: 로봇이 주어진 작업을 효율적으로 수행하도록 학습함  
- 자율 주행: 자동차가 도로 상황에 맞게 주행 전략을 학습함  
- 추천 시스템: 사용자의 반응을 기반으로 개인화된 콘텐츠를 추천함  

|구분 | 유형 | 알고리즘 | 
|------|---|------|
|지도학습(Supervised learning)|분류|K-최근접 이웃(K-Nearest Neighbor. KNN),서포트 벡터 머신(Support Vector Machine.SVM), 결정 트리(Decision tree),로지스틱 회귀 (logistic regression)|
|       | 회귀| 선형회귀(Linear Regression)| 
| 비지도학습(Unsupervised learning)|군집|K-평균 군집화 (K-means clustering) 밀도 기반 군집 분석 (DBSCAN) |
|    | 차원 축소| 주성분 분석|
|강화학습(Reinforcement learning)| -  |마르코프 결정 과정(Markov Decision Process, MDP)  |

### 사전 지식  
독립변수와 종속변수  
독립 변수 X -> 모델 -> 종속변수 Y  
독립변수(Independent Variable):     
 - 종속변수에 영향을 주는 변수   
 - 모델이 입력값으로 사용하는 변수  

종속변수(Dependent Variable):   
 - 다른 변수(독립변수)에 의해 영향을 받는 변수   
 - 예측하려는 목표 변수

예시
 마케팅 분석  
- 독립변수: 광고 비용, 프로모션 횟수  
- 종속변수: 매출액  
 부동산 가격 예측  
- 독립변수: 면적, 방 개수, 위치  
- 종속변수: 주택 가격  
 운동과 체중 감량  
- 독립변수: 운동 시간, 칼로리 섭취량  
- 종속변수: 체중 변화  
   
관계   
"독립변수(X)가 변하면 종속변수(Y)도 변한다."    
수식 예제:   
Y = aX + b   
- X: 독립변수     
- Y: 종속변수   
- a, b: 계수 a-기울기 b-절편   
   
평균(Mean, Average)과 분산(Variance)  
평균 (Mean)중앙값(Median)과 다름  
- 데이터 값들의 대표적인 중심값  
- 값을 모두 더한 후 개수로 나눈 값  
예시  
- 시험 점수: 70, 80, 90의 평균  
- (70 + 80 + 90) ÷ 3 = 80   
- 월간 판매량: (100, 120, 140) → 평균: 120개   
분산 (Variance)  
- 데이터가 평균을 기준으로 얼마나 퍼져 있는지 나타내는 값  
- 값이 클수록 데이터가 분산되어(흩어져) 있음  
핵심 요약  
평균: 데이터의 중심값  
분산: 데이터가 퍼진 정도  
 평균이 같아도 분산이 다를 수 있음!  
예:  
- (78, 80, 82) 평균 = 80, 분산 작음   
- (60, 80, 100) 평균 = 80, 분산 큼   
   
### 딥러닝 문제해결 과정  

1. 해결할 문제 정의 -> 2.데이터 수집 -> 3. 데이터 가공(데이터 전처리) -> 4. 딥러닝 모델 설계(모델구조 구현) 5. 딥러닝 모델 학습 -> 6. 성능 평가  

----
## 3주차 텐서플로 기초
### 벡터, 행렬, 텐서
• 인공지능(머신 러닝/딥러닝)에서 데이터는 벡터(vector)로 표현  
• 벡터는 [1.0, 1.1, 1.2]처럼 숫자들의 리스트로, 1차원 배열 형태  
• 행렬(matrix)은 행과 열로 표현되는 2차원 배열 형태  
• 텐서는 3차원 이상의 배열 형태  
  
#### 텐서플로(tensorflow)
데이터 흐름 그래프(data flow graph)를 사용하여 데이터의 수치 연산을 하는 오픈 소스 소프트웨어 프레임워크  
텐서플로에서 데이터의 수치 연산을 수행하기 위한 그래프   
그림과 같이 그래프의 노드(node)는 수학적 연산을 처리하고, 에지(edge)는 노드 사이의 관계를 표현하며, 데이터(텐서(tensor)) 이동을 수행   
  
텐서플로 아키텍처  
• 준비된 데이터를 사용하여 모델(모형)을 생성하고 저장할 수 있음  
• 생성된 모델을 사용하여 분류 및 예측으로 마무리할 수도 있지만, 텐서플로 허브(TensorFlow Hub)에 게시하여 재사용할 수도 있음 또한, 사용자에게 웹이나 모바일로 서비스를 배포할 수 있는 환경도 제공됨  
  
모델(모형)생성 -> 모델(모형) 저장 -> 모델(모형) 배포   
  
모델(모형) 생성:  
• 데이터 훈련을 위한 데이터셋과 모델을 생성하고 훈련할 수 있는 환경을 제공함  
• 모델의 학습 과정을 시각화하여 보여 줄 수 있는 텐서보드 같은 도구들을 제공  
• 모델(모형) 저장:  
• 텐서플로는 분산 환경에서 모델을 저장하고 배포할 수 있는 환경을 제공  
• 특히 웹이나 모바일 같은 다양한 환경에서 사용 가능하도록 호환성이 고려된 모델 저장소를 제공  
• 모델(모형) 배포:  
• 서버나 웹 환경에서 텐서플로를 사용하면 언어 및 플랫폼에 상관없이 모델을 쉽게 학습시키고 배포할 수 있음  
• 텐서플로 2.x에서는 포맷을 표준화하기 때문에 플랫폼과 컴포넌트 간 호환성도 확보할 수 있음  
텐서보드: epoch에 따른 accuracy 정확도 를 정리해준 표를 제공해줌.  

### 텐서플로의 주요 문법 model.complie() model.fit() model.evaluate() model.predict() 
모델 컴파일(model.compile) 과정에서의 주요 파라미터  
모델을 훈련하기 전에 필요한 파라미터들을 정의함  
주요 파라미터는 optimizer, loss function, metrics임.  
- 옵티마이저(optimizer): 데이터와 손실 함수를 바탕으로 모델의 업데이트 방법을 결정함(Adam, Nadam....)  
- 손실 함수(loss function): 훈련하는 동안 출력과 실제 값(정답) 사이의 오차를 측정함   
wx+b를 계산한 값(모델의 예측)과 y(정답)의 오차를 구해서 모델 정확성을 측정함 (예) MSE 등   
- 지표(metrics): 훈련과 검증 단계를 모니터링하여 모델의 성능을 측정(Accuracy[ 0 ~ 1 ]...)  
  
model.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])  
ⓐ 아담(Adam) 옵티마이저를 사용  
ⓑ sparse_categorical_crossentropy는 다중 분류에서 사용되는 손실 함수  
ⓒ 'accuracy'는 훈련에 대한 정확도를 나타내는 것으로, 값이 1에 가까울수록 좋은 모델  
   
모델 훈련(model.fit) 과정  
• 앞서 만들어 둔 데이터로 모형을 학습(학습용/검증용 데이터)   
• 학습을 시킨다는 것은 y=wx+b라는 매핑 함수에서 w와 b의 적절한 값을 찾는다는 의미   
• w와 b에 임의의 값을 적용하여 시작하며, 모델에 데이터를 입력하면서 오차를 구하게 됨   
• 이때 오차가 줄어드는 방향으로 파라미터를 수정  

model.fit(x_train, y_train, epochs=10, batch_size=100, validation_data=(x_test, y_test), verbose =2)  
ⓐ 입력 데이터  
ⓑ 정답(label) 데이터  
ⓒ 학습 데이터를 학습하는 횟수  
ⓓ 한 번에 학습하는 데이터의 개수  
ⓔ 검증 데이터(validation data)  
각 epoch마다 검증 데이터의 정확도도 함께 출력하게 할 수 있음. epoch 마다 validation으로 평가  
검증 데이터로 확인된 정확도는 훈련이 잘 되고 있는지 보여주는 지표로 사용할 수 있으며, 검증 데이터를 모델이 보면서 학습하지는 않음  
ⓕ verbose 학습 진행 상황을 보여 줄지 옵션을 지정함  
    
모델 평가(model.evaluate) 과정  
• 주어진 검증 데이터셋을 사용하여 모델을 평가함   
• 평가가 끝나면 검증 데이터셋에 대한 손실 값과 정확도가 결과로 표시됨   
    
model.evaluate(x_test, y_test, batch_size=32)  
ⓐ 검증 데이터셋  
ⓑ 결과(label) 데이터셋  
ⓒ 한 번에 학습할 때 사용하는 데이터 개수  

모델 사용(model.predict) 과정  
• 훈련된 모델을 사용하여 다음 예시 코드처럼 실제 예측을 진행함  
model.predict(y_test)  

### 실습 환경세팅
anaconda prompt 가상환경 dl 생성  
conda create -n dl  
conda activate dl   
pip install tensorflow  

모델 정의할 때  

Sequential API  
간결하며 대부분의 문제에 적합하다.  
model = tf.keras.sequential()  
model.add(Dense(4, activation = '', input_shape = (4,), weights = (, ), name = ""))  
단순히 여러 개 쌓는 형태, 복잡한 모델 생성 한계  

Functional API  
복잡한 모델 생성에서 한계를 극복  
다중 입력과 다중 출력 정의 가능  
input_layer = Input(shape=(X.shape[1],)) 입력  
dense_layer_1 = Dense(15, activation = 'relu')(input_layer) 은닉1  
dense_layer_2 = Dense(10, activation = 'relu')(dense_layer_1) 은닉2  
output = Dense(y.shape[1], activation = 'softmax')(dense_layer_2) 출력  
model = Model(inputs = input_layer, outputs = output)  
입력 데이터 형태를 input() 파라미터로 사용해 입력층 정의  
이전 층을 다음 층의 입력으로 사용  
model()에 입력과 출력 정의  

## 머신러닝 핵심 알고리즘  
부지런한 학습자와 게으른 학습자  
부지런한 학습자(eager learner)  
데이터셋 내부의 관계를 일반화하고 이를 이용해 처음 보는 데이터의 결과를 예측  
ex) 의사결정나무, 규칙 유도  
주어진 데이터에 기초하여 식 y=f(X)와 같은 수학적 관계를 개발한 후, 새로운 데이터에 대한 결과를 예측   
입력변수와 타겟변수 간의 실제 관계를 가장 잘 근사시키려 함(타겟변수-정답, 실제관계-가설)   
게으른 학습자(lazy learner)  
간단한 방법  
학습용 데이터셋에서 비슷한 레코드를 검색해서 예측함  
학습용 데이터셋을 학습이 아닌 검색(lookup)용 테이블로 사용해서 입력변수들과 일치하는 레코드를 찾아 타겟변수를 예측함  
비슷한 레코드들은 n차원 공간에서 가까이 위치하고, 타겟 변수의 클래스가 같음을 이용함  
ex) k-NN 알고리즘의 기본적인 원리  

### k-NN(k-Nearest Neighbour) k-최근접 이웃
대표적인 lazy learner 기반 알고리즘  
학습용 데이터셋 전체를 ‘기억’한 후, 클래스를 모르는 레코드를 분류할 때 이 레코드의 입력변수들을 학습용 데이터 전체와 비교해서 가장 가까운 것을 찾음  
가장 가까운 학습용 레코드의 클래스 레이블이 시험용 레코드의 예측하고자 하는 클래스 레이블   
비모수적 (nonparametric) 방법으로, 일반화나 데이터셋의 분포를 찾으려는 시도를 하지 않음  
!)  
모수적 방법(parametric method): 관측 값이 어느 특정한 확률분포를 따른다고 전제한 후 그 분포의 모수(parameter)에 대한 검정을 실시하는 방법(가설을 세우고 그에 근사하게 다가가는 방식)   
비모수적 방법(nonparametric method): 관측 값이 어느 특정한 확률분포를 따른다고 전제할 수 없거나 또는 모집단에 대한 아무런 정보가 없는 경우에 실시하는 검정방법.(데이터 형태나 모양을 보고 유연하게 모델링)  
모수에 대한 언급이 없으며 분포무관 방법.   
  
일단 학습용 레코드를 기억하고, 시험용 레코드와 가장 가까운 학습용 레코드를 찾으면 됨   
데이터셋에 있는 어떤 레코드라도 n차원 공간에서 하나의 점으로 나타낼 수 있음  
n: 속성의 개수  
3차원을 초과하는 경우에는 시각화하기 어렵지만, 2차원 공간에서 할 수 있는 연산들은 n차원 공간에서 수행 가능함  

iris 붓꽃 데이터   

k는 클래스를 모르는 시험용 레코드를 예측할 대 고려해야 할 최근접 학습용 레코드의 개수
- k=1일 경우   
가장 가까운 레코드 하나를 찾아 그 레이블을 예측치로 간주함  
최근접한 학습용 레코드가 특이값이거나 클래스가 틀리게 입력된다면....
k=1) 단순하지만 특이값에 약하다.     
- k=3일 경우  
가까운 레코드 3개를 고려함   
그 레코드 중 과반수의 레코드의 레이블을 클래스로 예측함   
그 레코드 중 과반수 이상인 레이블로 클래스를 예측함   
타겟 레코드의 클래스를 투표로 결정하므로 2-클래스 문제일 경우 k값은 주로 홀수로 정함  
k>1) 다수결로 안정성이 높으나 k가 너무 크면 경계가 모호해짐  
  
### 근접성 척도  
k-NN 알고리즘의 유효성은 시험용 레코드를 기억된 학습용 레코드와 비교할 때 얼마나 비슷한가를 결정하는 것에 전적으로 달려 있음  
근접성 척도 : 두 레코드 사이의 유사도를 수량화함  
- 거리  
유클리드 거리, 맨해튼 척도, 쳬비셰프 척도  
- 상관관계 유사도
- 단순 매칭 계수
- 자카드 유사도
- 코사인 유사도

유클리드 거리  
2차원 공간에서 두 점 X(x1 , x2 )와 Y(	y1 ,y2 ) 사이의 거리  
Dinstance d = 루트[ (x1 - y1)** + (x2 - y2)** ]
n차원 공간으로의 일반화   

ex) 4차원 아이리스 데이터셋의 데이터 포인트 X=(4.9, 3.0, 1.4, 0.2), Y=(4.6, 3.1, 1.5, 0.2) 거리는?   
루트 0.3** + (-0.1)** + (-0.1)** + 0**      -> 루트 0.11   
   
신용점수와 연간수입 데이터  
pair A : X=(500, $40,000), Y=(600, $40,000)  
pair B : X=(500, $40,000), Y=(500, $39,800)  

신용점수는 수치는 100이지만 20% 줄었고 연간수입은 200이 줄었지만 20만원 수준임(단위가 다름)  
문제점  
각 속성들의 크기와 측정단위가 통일되지 않으면 통일이 필요함   
각 레코드 사이의 공정한 비교를 위해 데이터셋의 모든 속성은 측정 대상과 측정 단위에 관해 동질적(homogenous)일 필요가 있음   
문제 완화를 위해 입력값들을 정규화(normalization)하는 작업이 필요함    
   
정규화 방법  
범위 변환(Min-Max Nomalization) : 모든 속성들의 값을 특정 최소값, 최대값(예.0~1 사이로) 사이의 크기로 지정함   
Z-변환 (z-score Nomalization) : 각 값에서 평균을 뺀 후 표준편차로 나눔  
변환된 값들의 평균이 0이고, 표준편차가 1인 분포를 갖게 됨  
   
Z-변환  (값 - 평균)/표준편차 값들의 평균이 0, 표준편차 1   
꽃받침의 길이를 변환하면?  
최솟값: 4.3, 최댓값 : 7.9, 평균: 5.84, 표준편차: 0.83  
4.3과 7.9 사이의 값을 가졌지만 변환 후에는 변환 전 표준편차는 0.83이지만, 변환 후 1이 됨  

맨해튼(Manhattan) 거리  
빌딩이 늘어져있고 체크무늬의 거리임. 개별 속성 사이의 차이의 합  
X(1,2), Y(3,1)   
맨해튼 거리는   
x와 y x값의 차이2, y값 차이 1 | 2 + 1 = 3   

쳬비셰프(Chevyshev) 거리  
데이터셋에 있는 모든 속성들의 사이의 차이 중 최댓값  
X(1,2), Y(3,1)  
쳬비셰프 거리는  
x와 y x값의 차이2, y값 차이 1 |  가장 큰 값의 차이는 2    
X(1, 2, 3) Y(10, 20, 30) 이면 27  
  
민코프스키(Minkowski) 거리 척도로 일반화 가능  
p=1 : 맨해튼 거리  
p=2 : 유클리드 거리  
p=∞ : 쳬비셰프 거리  
   
- 척도 선택은 데이터 유형에 따라 함  
수치형 – 유클리드  
이진형 – 맨해튼, 해밍 거리  

k개의 최근접 이웃이 결정되면, k개 중 다수인 클래스가 예측 클래스임  
y’= maximum class(y1,y2, ''', yk)   
y’ : 시험용 데이터 포인트의 타겟 클래스에 대한 예측치  
yi : i번째로 가까운 이웃의 클래스  

가중치
k가 1보다 클 때, 최근접 이웃들은 타겟 클래스의 예측에 있어서 먼 이웃보다 발언권이 더 있어야 한다고 주장할 수 있음  
먼 이웃일수록 최종 클래스를 결정할 때 미치는 영향 감소  
모든 이웃들에게 가중치를 할당함으로써 반영할 수 있음 (**가까울수록 큰 가중치**)  
가중치는 예측 클래스를 계산하는 마지막 다중 투표 단계에 포함시킴  
가중치의 두 가지 조건  
이웃들로부터 주어진 데이터 포인트까지의 거리에 반비례함  
모든 가중치의 합이 1임  
가중치  
속성이 수치형일 때 잘 활용됨  
다른 유형의 속성을 수치형으로 변환해야 범주형으로 사용하는 경우보다 더 많은 정보를 얻을 수 있음  
속성이 범주형이면 두 점이 같으면 거리가 0, 두 점이 다르면 거리가 1임  
d(흐림, 맑음)=1, d(맑음, 맑음)=0  
속성이 순서형이고, 값이 3개 이상이면 순서형의 값을 0,1,2... 정수형으로 변환하여 수치형으로 다룰 수 있음  
수치형으로 변환하지 않고 거리를 구하면 같으면 0, 다르면 1 이렇게만 나타남  
## 4주차 머신러닝 알고리즘 
근접성 척도: 상관관계  
데이터 포인트 X와 Y 사이의 상관계수 : 둘 사이의 ‘선형‘ 관계에 대한 척도  
Pearson 상관계수  
-1~1 사이의 값  
-1이면 완전한 음의 상관관계, 1이면 완전한 양의 상관관계  
0이면 ‘선형’ 관계가 없음 (비선형 관계가 있을 수 있음)  
  *값의 차이보다 방향성과 경향이 중요한 데이터를 비교할 때   
2개의 데이터 포인트 X와 Y 사이의 상관계수  
Sxy : X와 Y의 공분산(covariance) Sx : X의 표준편차  
  
근접성 척도: 단순 매칭 계수
단순 매칭 계수(Simple Matching Coefficient, SMC)  
데이터셋이 이진형 속성을 가질 때 사용함    
전체 발생 횟수에서 0이나 1이 동시에 발생하는 횟수의 비율임  
  
근접성 척도: 자카드 유사도  
자카드 유사도(Jaccard similarity)  
X와 Y가 텍스트 문서라면?  
각 단어는 문서 행렬(document matrix), 또는 문서 벡터(document vector)라고 불리는 데이터셋에서 하나의 속성이 됨  
속성의 개수가 매우 많은 수천개의 속성을 다루는 경우가 발생  
두 문서 X, Y 비교 시 속성값의 대부분은 0이 됨  
= 두 문서가 같은 단어를 갖는 경우가 매우 드물다  
단어의 발생(occurrence)과 미발생(nonoccurrence)을 비교하면 큰 의미가 있는 정보를 얻기 어려움  
단순 매칭 유사도 척도에 ‘미발생‘ 횟수를 제외하고, 발생 횟수에 대해서만 유사도를 측정  

근접성 척도: 코사인 유사도
문서 벡터의 속성은 단어의 발생/미발생을 나타냈음  
단어의 존재/부존재가 아닌 발생 횟수를 이용해 더 많은 정보를 담은 벡터를 만들 수 있음  
  
결론  
게으른 학습자 모델은 데이터 마이닝 방법 중 가장 간단함  
핵심 기능은 학습용 데이터셋을 참조하거나 검색하는 것  
k-nn 모델에서는 크거나 작은 측정 단위를 가지는 속성이 유발하는 편향(bias)을 피하기 위해 정규화가 필요함  
시험용 레코드에 결측치가 있어도 매우 견고한(robust) 모델  
게으른 학습자 모델은 입력과 출력 사이의 관계를 설명할 수 없음(고차원일 때)  
k-nn 모델 구축은 ‘기억하기’이기 때문에 시간이 적게 소요됨  
클래스를 모르는 레코드를 분류하려면 시험용 레코드와 모든 학습용 레코드 사이의 거리를 계산해야 하여 학습용 데이터의 크기나 속성의 개수가 많으면 고비용이 들 수 있음  
k-nn 모델이 입출력 관계를 일반화하는 데에는 좋지 않지만, 학습용 레코드 사이에 존재하는 관계를 확장하는 데에 매우 효과적임  
순서형 값들을 정수값들로 변환하여 거리를 구할 수 있음  
양질의 분석 결과를 내기 위해 입력 속성들의 가능한 모든 값들이 포함된 학습용 레코드가 상당히 많아야 함  

### svm 
서포트 벡터 머신(SVM)  
패턴 인식, 텍스트 마이닝 등 많은 분야에서 좋은 성능을 보임  
컴퓨터과학, 통계학 수학적 최적화 이론으로부터 주요 개념들이 도출됨  
개념과 용어  
같은 클래스에 속하는 데이터 포인트들끼리 모여있도록 경계를 설정하는 분류 기법  
학습용 데이터셋에 대해 일단 경계를 정하면, 새로운 데이터를 분류할 때 경계 내부인지,외부인지 점검함  
일단 경계가 확정되면 대부분의 학습용 데이터는 불필요함  
- 모든 학습용 데이터가 불필요하다(X)  
필요한 데이터 포인트들은 경계를 찾고 수정하는 데 관여하는 서포트 벡터(핵심 포인트)들 뿐
- 서포트벡터는 경계를 support 하는 데이터 포인트들이며, 경계를 찾고 수정하는데 관여함
각 데이터 포인트들은 벡터이다  
- 데이터 포인트 : 많은 수의 속성값을 포함하는 데이터로 구성된 하나의 행  
    
서포트 벡터 머신의 경계 : 초평면(hyperplane)  
속성이 2개인 경우 2차원에 데이터 포인트가 결정되고, 그 데이터 포인트들을 클래스별로 나눌 수 있는 것은 직선 또는 곡선임  
속성이 3개인 경우 3차원에 데이터 포인트가 결정되고, 그 데이터 포인트들을 클래스별로 나눌 수 있는 것은 평면이거나, 복잡한 면이 있음  
고차원에서는 ‘초평면’이 경계에 대한 포괄적인 이름임  
서포트 벡터 머신의 경계 : 초평면(hyperplane)  
동일한 데이터셋에 대해 수많은 초평면이 있을 수 있음  
이 데이터 포인트들을 잘 나누는 가장 적절한 초평면을 고르는 것이 SVM의 목적  
클래스를 분리할 때 오류가 최소인 경계가 가장 좋은 경계  
두 구역 사이의 평균 거리(여백, margin)가 최대가 되도록 하는 경계가 가장 좋은 경계  
SVM 알고리즘은 본질적으로 여백을 최대화하는 최적화 기법을 수행함  
여백을 최대화하면 일반화 오차가 줄어듦  
서포트 벡터 : 경계의 구성에 영향을 주는 데이터 포인트들, 마진의 경계에 걸치는 샘플들  

항상 데이터가 깔끔하게 분리되기는 어렵다    
데이터가 선형 분리 가능(linearly separable)인 경우는 드물다  
선형분리가 되는 경우, 여백 안에 많은 점들이 존재하게 됨  
가장 좋은 초평면은 여백 안의 점들의 수가 최소가 되게 하는 초평면임    
여백 내부의 모든 ‘오염된(co ntaminant)’ 점들에 벌점(penalty)을 부과한 후, 총 벌점이최소인 초평면을 선택함  

선형 분리가 불가능한 경우 = 클래스 사이를 분리하는 평면, 직선이 없는 경우  
ex) 초평면(타원이나 원 등)이 클래스를 쉽게 분리할 수 있는 경우   
커널 함수(kernel function)를 이용해 선형분리가 가능한 형태로 변환  
커널 함수   
비선형 공간을 선형으로 변환하는 옵션 제공  
다양한 커널 함수들(다항식, 시그모이드 함수.. 등)  
사용자는 소프트웨어에서 적당한 커널 함수를 선택하면 됨(주로 다항식과 반지름 기반 함수를
사용함)  

선형 분리가 불가능한 경우에 분리할 수 있는 방법
두 변수 x,y로 이루어진 공간((x,y) 차원)을 x와 새로운 변수 z로 이루어진 공간 ((x,z) 차원)으로 변환시킴  
ex) z는 원의 방정식을 사용하여 변환하였음 -> 반지름에 대응하는 값이 나타남  
  
선형 분리가 불가능한 경우에 분리할 수 있는 방법  
변환된 공간에서 분류한 후, 다시 원래의 공간으로 역변환시킴  
  
핵심 단계들  
단계1 : 각 클래스의 경계를 찾음  
단계2 : 나누는 기준으로서 지정이 가능한 초평면들 중 각 경계까지의 거리를 최대로 하는
최선의 초평면 H를 찾음  
단계3 : 주어진 시험용 레코드를 분류하기 위해 초평면의 어느 쪽에 위치하는지 계산하여
판단함  

단계1 : 각 클래스의 경계를 찾음  
한 클래스에 해당하는 점들을 모두 연결하고, 그것의 외곽선인 convex hull(컨벡스 헐):[실제 계산 x)을 찾는다  
각 클래스는 자신의 convex hull을 갖고 있고, 클래스들이 선형 분리가 가능한 경우, convex
hull들은 서로 교차하지 않음  
  
단계2 : 최선의 초평면 H를 찾음  
가능한 초평면은 무한정 많음  
여백을 최대로 하는 초평면을 선택함  
수리최적화 이론 중 2차 계획법 문제로 여백을 최대로 하는 초평면을 찾음(수학적 결정)  
소프트웨어에서 제공하는 기능  
n개의 속성을 가진 데이터는 최소 n+1개의 서포트 벡터가 존재함  
서포트 벡터만 고려하여 경계를 결정하므로 수행 시간이 빠르다  
  
단계3 : 시험용 레코드를 분류함  
일단 경계와 초평면이 결정되면, 새로운 시험용 레코드를 분류할 때, 초평면의 어느 쪽에 놓여 있는지 계산함  
초평면의 수학식에 시험용 레코드 값을 대입하여 나온 계산값으로 클래스를 판별할 수 있음  
소프트웨어에서 제공하는 기능   
  
장점  
구축 후, 서포트 벡터가 변하지 않으면 소요 시간이 적음  
유용한 적용성(flexibility in application)  
이미지 프로세싱부터 사기 탐지, 텍스트 마이닝에 이르기까지 다양한 분야에 적용됨  
강건성(robustness)  
데이터의 변화가 작은 경우에는 리모델링하는 것이 불필요함  
반 과적합(overfitting resistance)  
데이터셋 내부의 클래스 경계는 소수의 서포트벡터만으로도 적절히 나타낼 수 있음  
단점  
속성의 수가 많으면(차원^) 어떤 커널 함수를 사용해야 할지 알기 어려우며, 2차식으로 시작하여 원하는 정확도 수준에 이를 때까지 점점 복잡한 함수를 이용해야 하므로 계산량이 많음  
고차원의 SVM은 계산량이 많아 구축시 시간 소요가 큼  
SVM은 학습시 모든 분류에 대해 dot product(내적) 연산을 하므로, 차원이 매우 높으면(=속성의 수가 많으면) 계산이 매우 느려짐  

### Decision Tree
• 결정 트리(Decision Tree, 의사결정 나무)  
• 결과 모델이 트리 구조이므로 결정 '트리'라고 함  
• 입력 데이터를 여러 단계의 질문(또는 조건)으로 나눠가면서  
각 단계마다 분기를 거치며, 결국 잎(leaf)에 도달하는 분석 방법  
• 장점: 해석이 쉬움, 시각화가 쉬움  
• 단점: 과적합 위험이 있음  
순도와 불순도   
• 결정 트리의 성능과 구조를 결정하는 핵심 기준  
• 순도(purity): 한 노드에 속한 데이터가 거의 모두 같은 클래스일 때, "순도가 높다"  
• 불순도(impurity): 한 노드에 여러 클래스가 섞여 있으면 "불순도가 높다"  
• 결정 트리는 학습 과정에서 불순도를 줄이는 방향으로 분기함  
• 결정 트리에서는 각 분기점에서 순도가 높아질수록 예측 정확도가 올라감  
• 불순도가 높은 노드는 더 분할해 순도를 높여야 하고, 순도가 충분히 높으면 그 부분을 잎(leaf) 노드로 결정함  
  
순도와 불순도 - 엔트로피, 지니계수  
• 순도가 증가하고 불확실성이 감소하는 것을 정보 이론에서는 정보 획득(information gain)이라고 하며, 불확실성을 계산하는 방법으로 엔트로피와 지니계수를 많이 사용함  
• 엔트로피(Entropy)  
: 확률 변수의 불확실성을 수치로 환산한 것  
엔트로피가 높을수록 불확실성이 높음.  
즉, 엔트로피 값이 0이면 불확실성이 최소 = 무질서 최소 = 순도 최대 = 같은 항목만 있음  
엔트로피 값이 1이면 불확실성이 최대 = 무질서 최대 = 순도 최소 = 각 항목이 같은 비율로 섞여 있음  
• 지니 계수(Gini Index)  
• 엔트로피 측정과 유사하지만 0과 0.5 사이임   
지니 계수 0 = 불순도 최소  
지니 계수 0.5 = 불순도 최대   
  
혼동행렬(confusion matrix)  
혼동 행렬은 알고리즘 성능 평가에 사용됨  
True Positive: 모델이 ‘1’이라고 예측했는데 실제 값도 ‘1’인 경우  
True Negative: 모델이 ‘0’이라고 예측했는데 실제 값도 ‘0’인 경우  
False Positive: 모델이 ‘1’이라고 예측했는데 실제 값은 ‘0’인 경우  
False Negative: 모델이 ‘0’이라고 예측했는데 실제 값은 ‘1’인 경우  
혼동행렬(confusion matrix)  
잘못된 예측(파)보다는 정확한 예측(빨)의 수치가 더 높으므로 잘 훈련되었다고 할 수 있음  
랜덤 포레스트(random forest)  
- 여러 개의 결정 트리를 무작위로 만들어서, 그 결과를 종합해 최종 예측을 내리는 앙상블(ensemble) 학습 방법  
- 하나의 결정 트리만 사용할 때보다 과적합 위험이 적고, 예측 정확도가 높아짐  
### Logistic Regression
Logistic Regression(로지스틱 회귀)  
**분류 문제**를 풀기 위한 지도 학습 알고리즘  
입력 변수들의 값과 가중치를 선형 결합한 후, 그 결과를 시그모이드 함수를 통해 0과 1사이의 확률값으로 변환함  
이 확률 값을 기준으로 분류(클래스 0 or 클래스1)함 + 이진분류 뿐만 아니라 다중 분류에도 적용 가능  
(예) 이진분류에서  
P(Y=1) ≥ 0.5 → class 1로 분류  
P(Y=1) < 0.5 → class 0으로 분류  
(복습)  
• 독립 변수: 영향을 미칠 것으로 예상되는 변수  
• 종속 변수: 영향을 받을 것으로 예상되는 변수  

- 선형 회귀(Linear Regression)  
: 입력된 변수들로부터 연속적인 숫자값을 예측함  
(예) 집값, 키, 온도 등의 실수값  
- 로지스틱 회귀(Logistic Regression)  
:입력 변수로부터 이진분류(또는 다중분류)를 수행함  
(예) 합격/불합격, 스팸/정상메일 분류 등

평균제곱오차 (MSE, Mean Squared Error)  
:예측값과 실제값의 차이(오차)를 각각 제곱해서 모두 더한 뒤, 데이터 개수로 나눈 값  
루트 평균제곱오차(RMSE, Root Mean Squared Error)  
: MSE에 루트만 씌운 값(0~5값 4.12면 오차가 상당히 큼)  
#### 실습

----  

## 05주차 비지도 학습  
### K-means clustering
• 데이터를 입력받아 K개의 군집으로 묶는 알고리즘  
• 레이블이 없는 데이터를 입력받아 각 데이터에 레이블을 할당해서 군집화를 수행함  
• (idea) 데이터들을 비슷한 것들끼리 묶되, 각 군집 내부는 최대한 서로 가깝게, 서로 다른 그룹끼리는 최대한 멀게 만들자  
• 즉, 알고리즘은 클러스터 내의 데이터포인트들의 거리들이 최소화되는 방향으로 진행됨  
SSD 지표 (sum of Squared Distance) 사용  
과정  
1. 중심점 선택: K값을 선택한 후 랜덤하게 초기 중심점(centroid)을 선택함  
2. 클러스터 할당: K개의 중심점과 각각의 개별 데이터 간의 거리(distance)를 측정한 후, 가장 가까운 중심점을 기준으로 데이터를 할당함  
- 이 과정을 통해 클러스터(군집)가 구성됨  
3. 새로운 중심점 갱신(Update): 클러스터마다 새로운 중심점을 계산함  
4. 수렴 판단(convergence):  
- 중심점의 위치가 더이상 변하지 않거나,  
- SSD(Sum of Squared Distances) 감소량이 매우 작아지면 알고리즘을 종료함  
- 만약 계속 변화가 있다면 SSD가 최소화될 때까지 2~4 과정을 반복   
converge: 한점으로 모이다.  
단점:  
데이터가 비선형일때.(이유: 군집크기를 직접 조정해줘야함)  
군집 크기가 매우 다를 때      
군집마다 밀집도와 거리가 다를 때    

실습  
데이터 정보  
Channel: 고객 채널(호텔/레스토랑/카페) 또는 소매 채널(명목형 데이터)  
Region: 고객 지역(명목형 데이터)  
Fresh: 신선한 제품에 대한 연간 지출(연속형 데이터)  
Milk: 유제품에 대한 연간 지출(연속형 데이터)  
Grocery: 식료품에 대한 연간 지출(연속형 데이터)  
Frozen: 냉동 제품에 대한 연간 지출(연속형 데이터)  
Detergents_Paper: 세제 및 종이 제품에 대한 연간 지출(연속형 데이터)  
Delicassen: 조제 식품에 대한 연간 지출(연속형 데이터)  
  
명목형 데이터(전처리 필요)  
|데이터 형태 | 설명 | 예시 | 
|------|---|------|
|수치형 자료| 관측된 값이 수치로 측정되는 자료| 키, 몸무게, 시험 성적|
|연속형 자료| 값이 연속적인 자료 | 키, 몸무게 |
|이산형 자료| 셀 수 있는 자료| 자동차 사고(소숫점으로 나타내지 않음)|  
|범주형 자료| 관측 결과가 몇 개의 범주 또는 항목의 형태로 나타나는 자료| 성별(남, 여), 선호도(좋, 싫)|
|순위형 자료|범주 간에 순서 의미가 있는 자료|'매우 좋다', '좋다', '보통이다', '싫다', '매우 싫다' 다섯가지 범주가 주어졌을 때, 이 범주에는 순서가 존재|
|명목형 자료|범주 간에 순서 의미가 없는 자료| 혈액형 |

k-means 알고리즘은 SSD 값이 줄어드는 방향으로 학습이 진행됨  
elbow point 근처 값을 선택  
SSD(Sum of Squared Distances)  
: 중심점으로부터 각 군집 내의 데이터 포인트들의 거리의 제곱을 모두 더한 값  
계산  
|클러스터 이름|중심점(센트로이트)|데이터 포인트|거리(제곱)|SSD|
|------|---|------|------|------|
|C1|(2,2)|(1, 2), (2, 1), (3, 2)|1 + 1 + 1| 3 |
|C2|(7,7)|(6, 8), (8, 6), (7, 9)|루트 2제곱 + 루트 2제곱 + 2 제곱| 8 |  
  
전체 SSD 3 + 8 = 11    
SSD   
• K가 증가하면 거리 제곱의 합은 0에 가까워지는 경향이 있음  
• K를 최댓값 n(여기에서 n은 샘플 개수)으로 설정하면 각 샘플이 자체 클러스터를 형성하여 거리 제곱 합이 0과 같아지기 때문임  
• 출력 그래프는 클러스터 개수(x축)에 따른 거리 제곱의 합(y축)을 보여 줌  
• K가 6부터 0에 가까워지고 있으므로 K=5가 적정하다고 판단할 수 있음  
### DBSCAN
• DBSCAN(Density-Based Spatial Clustering of Applications with Noise, 밀도 기반 군집 분석)  
• 데이터의 밀도를 기준으로 클러스터를 자동으로 찾아주는 알고리즘  
• K-means 알고리즘에서는 클러스터의 수 k를 미리 정해줘야 했지만, DBSCAN에서는 클러스터의 수가 자동으로 결정됨  
• DBSCAN은 K-means와 다르게 비선형 등 다양한 모양의 군집화도 처리할 수 있음  
• 노이즈는 클러스터에 포함하지 않고 따로 분류함  
노이즈(noise)에 영향을 덜 받으며, K-평균 군집화에 비해 연산량은 많지만 K-평균 군집화가 잘 처리하지 못하는 오목하거나 볼록한 부분을 처리하는 데 유용함  
밀도가 높은 지역(데이터 포인터가 많이 모여있는 지역)을 하나의 클러스터로 봄.  
• 밀도를 판단할 때 사용하는 개념:  
• ε(epsilon): 반경(이 거리 안에 몇 개의 점이 있는가를 세는 기준)  
• **minimum points(MinPts)**: 클러스터로 인정되기 위한 반경 내의 최소 점의 수  
• Core Point (핵심점): 반경 ε 안에 MinPts 이상의 점이 있는 점, 밀도가 높은 중심 지역의 점(클러스터의 중심 부분에 들어가 있는 점, 중심점이 아니다.)   
• Border Point (경계점): Core Point 근처에 있지만, 자기 주변에는 MinPts 이상이 없는 점(클러스터 가쪽 포인트)    
• Noise Point (잡음점): 어떤 클러스터에도 속하지 않는 외딴 점   
DBSCAN 과정  
1. 아직 방문하지 않은 점 하나를 임의로 선택함   
2. 그 점 주변(ε 반경) 이웃 탐색  
 : ε 거리 안에 몇 개의 점이 있는지 확인함  
 : 만약 이웃 수 ≥ MinPts → 핵심점(Core Point)으로 인정  
 : 그렇지 않으면 임시로 Noise로 표시 (하지만 나중에 다른 클러스터에 포함될 수도 있음)  
3. 핵심점이면 클러스터 확장 시작  
 : 그 점의 이웃점들 중 핵심점인 점들을 계속 찾아서 연결된 모든 점을 같은 클러스터로 묶습니다.  
 → 이 과정을 밀도 기반 확장 (density expansion) 이라 부름  
4. 더 이상 새로운 점이 연결되지 않을 때 (확장 불가능), 지금까지 찾은 점들로 하나의 클러스터 완성  
5. 다시 아직 방문하지 않은 점으로 이동  
 : 여기에서도 같은 과정을 반복함 (새로운 클러스터가 생성됨)  
6. 모든 점이 방문될 때까지 반복  
결국, 밀도 높은 구역은 여러 개의 클러스터로 만들어지고, 어디에도 속하지 않는 외딴 점들은 Noise로 남게 됨  
### PCA
PCA(Principal Component Analysis, 주성분 분석)  
• 데이터의 차원을 줄이면서도 핵심 정보를 최대한 보존하는 기법  
• 데이터 분석, 시각화, 머신러닝 전처리에서 가장 많이 쓰이는 차원 축소 방법  
• 데이터의 분산이 가장 큰 방향을 찾아서 데이터를 새로운 축(주성분, principal component)으로 재표현함  
• 즉, 데이터를 더 적은 변수로 요약하되, 가장 중요한 패턴(정보)은 잃지 않도록 하는 기법  
• 변수가 너무 많으면 -> 차원을 줄여 계산량과 복잡도를 줄임  
• 서로 다른 변수들 간 상관관계가 높으면? -> 중복된 특성들을 제거함  
• 노이즈가 많은 데이터 -> 중요하지 않은 축을 제거해 구조를 명확히 할 수 있음  
• 데이터를 시각적으로 보고 싶으면 -> 특성의 수를 줄여 2D, 3D 공간으로 투영해 시각화 가능  
  
• 데이터들의 분포 특성을 잘 설명하는 벡터를 두 개 선택하기  
• 다음 그림에서 e1과 e2 두 벡터는 데이터 분포를 잘 설명함  
• e1의 방향과 크기, e2의 방향과 크기를 알아내어 주성분을 결정함  
• 고유벡터: 데이터가 퍼져있는 방향  
• 고유값: 그 방향으로의 분산 크기(정보량)  
•e₁ 방향(제1주성분)은 데이터 분산이 가장 큰 방향  
•e₂ 방향(제2주성분)은 e₁과 직교하면서 그다음으로 분산이 큰 방향  
•고유값(벡터의 크기)이 클수록 해당 주성분이 데이터의 특성을 더 잘 설명함  
• e₁: 데이터의 분산이 가장 큰 방향 (제1주성분, PC1)  
• e₂: e₁과 직교하면서, 그 다음으로 분산이 큰 방향 (제2주성분, PC2)  
• e₁이 가장 많은 분산(정보)을 담고, e₂가 그 다음, e₃는 더 적음   
• (예) e₁이 전체 분산의 65%를 설명하고, e₂가 전체 분산의 25%를 설명함. 두 개의 주성분으로 전체 분산의 90%를 설명할 수 있음  
•주성분을 몇 개를 선택해야 할까?  
•데이터의 정보량(분산 비율)을 기준으로 결정하면 됨  
•"전체 분산 중 몇 %를 설명하면 되는가?"를 기준으로    
•(예) 90% 이상의 정보를 설명하고 싶을 때: 2개  
•(예) 95% 이상의 정보를 설명하고 싶을 때: 3개  
과정  
1. 데이터 전처리 - 센터링(Centering): 각 변수의 평균으로 0으로 맞춤 - 표준화(Standardization): 단위가 다르면 각 변수의 범위를 조정함  
2. 공분산 행렬 계산 - 변수간의 분산과 상관관계를 나타내는 행렬을 계산하여 데이터의 분포 방향을 파악함  
3. 고유값 분해(Eigen Decomposition) - 데이터 분포의 방향과 그 방향의 분산(정보량)을 파악함  
4. 주성분 선택 - 고유값이 큰 순서대로 정렬하여 누적 설명분산비율(Explained Variance Ratio)로 선택할 주성분의 수를 결정함  
5. 데이터 투영(Projection) - 원래 데이터 X를 선택한 주성분 축에 투영하여, 차원이 축소된 데이터 Z를 생성함 - 가장 중요한 정보만 남은 상태  
#### (실습) PCA + DBSCAN  
• PCA로 데이터 전처리 후, DBSCAN 적용하여 군집화  

## 딥러닝 
딥러닝 구조
• Deep Neural Network는 다음 그림과 같이 입력층, 출력층 사이에 두 개 이상의 은닉층으로 구성됨  
• 입력 신호를 전달하기 위해 다양한 함수를 사용함  
| 구분 | 구성 요소 | 설명 |
| :--- | :--- | :--- |
| **층** | 입력층(input layer) | 데이터를 받아들이는 층 |
| | 은닉층(hidden layer) | 모든 입력 노드부터 입력 값을 받아 가중합을 계산하고, 이 값을 활성화 함수에 적용하여 출력층에 전달하는 층 |
| | 출력층(output layer) | 신경망의 최종 결과값이 포함된 층 |
| **가중치(weight)** | | 노드와 노드 간 연결 강도 |
| **바이어스(bias)** | | 가중합에 더해 주는 상수료, 하나의 뉴런에서 활성화 함수를 거쳐 최종적으로 출력되는 값을 조절하는 역할을 함 |
| **가중합(weighted sum), 전달 함수** | | 가중치와 노드의 곱을 합한 것 |
| 함수 |**활성화 함수(activation function)** | 신호를 입력받아 이를 적절히 처리하여 출력해 주는 함수 |
|  |  **손실 함수(loss function)** | 가중치 학습을 위해 출력 함수의 결과와 실제 값 간의 오차를 측정하는 함수 |
용어  
가중치(Weight)  
• 입력 값이 연산 결과에 미치는 영향력을 조절하는 요소  
• 가중치 값이 0 혹은 0과 가까운 0.001이라면, x1이 아무리 큰 값이라도 가중치를 곱한 값은 0이거나 0에 가까운 값이 됨  
• 이와 같이 입력 값의 연산 결과를 조정하는 역할을 하는 것이 가중치  
가중합(전달 함수, transfer function)  
• 각 노드에서 들어오는 신호에 가중치를 곱해서 다음 노드로 전달되는데, 이 값들을 모두 더한 합계를 가중합이라고 함  
• 이 가중합이 활성화 함수로 보내지므로, 전달 함수(transfer function)라고도 함  
활성화 함수(activation function)  
• 전달 함수(가중합)에서 전달받은 값을 출력할 때 일정 기준에 따라 출력 값을 변화시키는 비선형 함수  
• (예) 시그모이드(sigmoid), 하이퍼볼릭 탄젠트(hyperbolic tangent), 렐루(ReLU) 함수 등  

### 활성화 함수 
Sigmoid  
시그모이드 함수  
선형 함수의 결과를 0~1 사이에서 비선형 형태로 변형해 줌  
주로 로지스틱 회귀와 같은 분류 문제를 확률적으로 표현하는 데 사용  
결괏값의 평균이 0이 아닌 양수로 편향된 문제가 있음  
딥러닝 모델의 깊이가 깊어지면 기울기가 사라지는 ‘기울기 소멸 문제(vanishing gradient problem)’가 발생하여 딥러닝 모델에서는 잘 사용하지 않음  
Hyperbolic tangent  
하이퍼볼릭 탄젠트 함수   
• 선형 함수의 결과를 -1~1 사이에서 비선형 형태로 변형해 줌  
• 시그모이드에서 결괏값의 평균이 0이 아닌 양수로 편향된 문제를 해결하는 데 사용했지만, 기울기 소멸 문제는 여전히 발생  
ReLU  
렐루 함수  
• 입력(x)이 음수일 때는 0을 출력하고, 양수일 때는 x를 출력  
• 경사 하강법(gradient descent)의 기울기 계산이 단순하여 학습이 빠름  
• 렐루 함수는 일반적으로 은닉층에서 사용되며, 하이퍼볼릭 탄젠트 함수 대비 학습 속도가 대체로 빠름  
• 음수 값을 입력받으면 항상 0을 출력하기 때문에 학습 능력이 감소하는 문제가 발생함  
Leaky ReLU  
리키 렐루 함수   
• 입력 값이 음수이면 0이 아닌 0.001처럼 매우 작은 수를 반환함  
• 입력값이 음수일 때도 작은 기울기를 남겨서 죽은 ReLU문제를 완화할 수 있음(+속도 상승, 기울기문제완화)  
Softmax
소프트맥스(Softmax) 함수(은닉, 출력층에서 사용하는 활성화함수 중 출력에서 주로 사용)  
• 입력 값을 0~1 사이에 출력되도록 정규화하여 출력 값들의 총합이 항상 1이 되도록 함  
• 딥러닝에서 출력 노드의 활성화 함수로 많이 사용함  
$$ y_{k} = \frac{e^{a_{k}}}{\sum_{i=1}^{n} e^{a_{i}}} $$

* 이 수식은 일반적으로 다중 클래스 분류 문제에서 **신경망의 최종 출력**을 **확률 분포**로 변환할 때 사용됩니다.  
* $a_k$는 신경망의 마지막 계층에서 계산된 $k$번째 **출력 값(로짓, Logit)**을 나타냅니다.  
* $y_k$는 모든 클래스에 대한 출력 값의 총합 중 $k$번째 클래스에 해당하는 값의 비율, 즉 $k$번째 클래스일 **확률**을 의미합니다.  
* 모든 $y_k$ 값의 합은 항상 **1**이 됩니다.  
• ak : k번째 출력 뉴런의 입력값  
• eak : 지수함수 (exponential function)  
• n: 출력 노드의 개수 (예: 분류 클래스 수)  
• yk : k번째 클래스의 “확률” 값  
  
---순전파---   
---역전파---  
손실 함수(loss function)  
• 오차를 구할 때 사용하는 함수  
• 학습을 통해 얻은 데이터의 추정치가 실제 데이터와 얼마나 차이가 나는지 평가하는 지표  
• 값이 클수록 많이 틀렸다는 의미, 값이 ‘0’에 가까우면 완벽하게 추정할 수 있다는 의미  
• (예) 평균 제곱 오차(Mean Squared Error, MSE), 크로스 엔트로피 오차(Cross Entropy Error, CEE) 등  
경사 하강법(Gradient Descent)  
• 손실함수의 기울기를 따라 가장 낮은 곳(오차가 최소인 지점)으로 내려가는 아이디어에서 시작함  
• 경사 하강법은 학습률(learning rate)과 손실 함수의 순간 기울기를 이용하여 가중치를 업데이트하는 방법  
• 즉, 손실함수의 값을 최소화하는 방향으로 이동 시키는 방법임  

### 손실 함수 
MSE  
평균 제곱 오차(MSE, Mean Squared Error)  
• 실제 값과 예측 값의 차이(error)를 제곱하여 평균을 낸 것  
• 실제 값과 예측 값의 차이가 클수록 평균 제곱 오차의 값도 커짐  
• 회귀에서 손실 함수로 주로 사용함  
크로스 엔트로피 오차(CEE, Cross Entropy Error)  
• 분류(classification) 문제에서 원-핫 인코딩(one-hot encoding)과 주로 함께 사용되는 오차 계산법  
• "정답 클래스의 확률을 얼마나 높게 예측했는가?"를 계산함.  
• 즉, 확률이 낮으면 큰 벌점을, 높으면 작은 벌점을 주며 값을 수정함  
공식을 보면 계산할 수 있어야함.  
^  
y = softmax의 결과로 출력층에 나온 예측의 확률  
지역 최소점(local minimum)과 전역 최소점(global minimum)  
• 손실 함수의 값은 0이 가장 이상적임  
• 현실적으로 0을 찾는 것은 쉽지 않기 때문에 최대한 가장 작은 값을 찾는 것이 중요함  
• 그래프의 일부 구간에서 보면 더 이상 내려갈 수 없는 지점이 지역 최소점  
• 하지만 전체 그래프를 보면 더 낮은 지점이 있을 수 있음  
• 전체 그래프에서 가장 낮은 지점이 전역 최소점(오차가 가장 작은 지점)  
local minima, global minima  
현실에서는 계산 복잡도와 랜덤 (가중치) 초기화 문제 때문에 항상 전역 최소점을 찾는 것은 어렵다.  

순전파(feedforward)와 역전파(backpropagation)  
순전파(feedforward)는 네트워크에 훈련 데이터가 들어올 때 발생하며, 데이터를 기반으로 예측 값을 계산하기 위해 전체 신경망을 교차해 지나감  
즉, 모든 뉴런이 이전 층의 뉴런에서 수신한 정보에 가중합 및 활성화 함수를 적용하여 다음 층(은닉층)의 뉴런으로 전송하는 방식  
데이터가 모든 층을 통과하고 모든 뉴런이 계산을 완료하면 그 예측 값은 최종 층(출력층)에 도달하게 됨  
그다음 손실 함수로 네트워크의 예측 값과 실제 값 차이(손실, 오류)를 추정함
손실 함수 비용이 0에 가깝도록 하기 위해 모델이 훈련을 반복하면서 가중치를 조정함  
손실이 계산되면 그 정보는 역으로 전파(출력층 → 은닉층)되기 때문에 역전파(backpropagation)라고 함  
출력층에서 시작된 손실은 은닉층의 모든 뉴런으로 전파되지만, 은닉층의 뉴런은 각 뉴런이 원래 출력에 기여한 가중치에 따라 값이 달라짐  
예측 값과 실제 값 차이를 각 뉴런의 가중치로 미분한 후 기존 가중치 값에서 뻼  
이 과정을 출력층 → 은닉층 순서로 모든 뉴런에 대해 진행하여 계산된 각 뉴런 결과를 또다시 순전파의 가중치 값으로 사용함  

### 딥러닝의 문제점  
• 딥러닝의 핵심은 활성화 함수가 적용된 여러 은닉층을 결합하여 비선형 영역을 표현하는 것  
• 일반적으로 활성화 함수가 적용된 은닉층 개수가 많을수록 데이터 분류가 잘 됨  
• 하지만, 은닉층이 많을수록 생기는 문제가 있음 - 과적합 문제, 기울기 소멸 문제, 성능 저하 문제  
과적합 문제  
과적합(Overfitting) 문제 발생  
• 훈련 데이터를 과하게 학습해서 발생하는 문제  
• 일반적으로 훈련 데이터는 실제 데이터의 일부분이므로, 훈련 데이터를 과하게 학습하면 검증 데이터에 대해서는 오차가 증가할 수도 있음  
• 즉, 과적합은 훈련 데이터에 대해 과하게 학습하여 실제 데이터에 대한 오차가 증가하는 현상을 의미함  
과적합(Overfitting) 해결 방안 - 드롭아웃(Dropout)  
• 학습 과정 중 임의로 일부 노드들을 학습에서 제외시킴  
드롭아웃(랜덤으로) 적용  

------------
성능 저하 문제 발생
• 경사 하강법은 손실 함수의 비용이 최소가 되는 지점을 찾을 때까지 기울기가 낮은 쪽으로 계속 이동시키는 과정을 반복하는데, 이때 성능이 나빠지는 문제가 발생할 수 있음
• 일단, 모든 데이터를 한 번에 사용해서 오차를 계산하고 기울기를 구해 내려가게 되는데(Batch Gradient Descent), 매번 계산량이 너무 크고, 지역 최소점에 빠지면 탈출하기 어렵고, 평평한 구간에서 거의 움직이지 않는 현상이 발생하게 됨
[해결책]  
- Stochastic Gradient Descent(확률적 경사 하강법)  
- Mini-Batch Gradient Descent(미니 배치 경사 하강법)  

배치 경사 하강법(Batch Gradient Descent) 일반적인 방법: 전체를 보고 업데이트.   
확률적 경사 하강법(Stochastic Gradient Descent) 데이터를 확률적으로 나누어 업데이트   
미니 배치 경사 하강법(Mini-Batch Gradient Descent) 작은 묶음으로 나누어 업데이트   
  
확률적 경사 하강법(SGD, Stochastic Gradient Descent)  
• 임의로 선택한 데이터 1개에 대해 기울기를 계산해 곧바로 가중치를 업데이트하는 방법  
• 적은 데이터를 사용하므로 빠른 계산이 가능함  
• 학습 경로가 흔들리면서 지역 최소점을 벗어날 확률이 높아짐  
• 실시간으로 들어오는 데이터를 바로 반영할 수 있음  
• 단, 샘플 하나만 보고 판단하므로 기울기의 방향이 매번 다르며, 손실값이 요동쳐 오차가 들쭉날쭉함  
model.fit(X_train, y_train, batch_size = 1)  

미니 배치 경사 하강법(Mini-Batch Gradient Descent)
• 전체 데이터셋을 미니 배치(mini-batch) 여러개로 나누고, 미니 배치한 개마다 기울기를 구한 후 그것의 평균 기울기를 이용하여 모델을 업데이트해서 학습하는 방법  
• 전체 데이터를 보고 학습하는 것보다 빠르며, 확률적 경사 하강법보다 안정적이라는 장점이 있음 -> 많이 사용됨  
• 학습 경로가 SGD에 비해 안정적이면서 속도도 빠름  
model.fit(X_train, y_train, batch_size =32)  

그래프 확인  
|방식 | 한 번의 업데이트에 사용하는 데이터 수| 1 epoch 동안의 업데이트 횟수| 
|------|---|------|
|Batch GD| 10,000개 |1번|
|SGD|1개|10000번|
|Mini-Batch GD|예: 100개|100개 기울기에 대해 평균을 구해 한 번 가중치 업데이트|

### 옵티마이저(Optimizer)
모델이 손실을 줄이기 위해 기울기를 구하게 되는데, 그 기울기를 이용해 가중치를 얼마나, 어떤 방식으로 업데이트할지 결정하는 알고리즘  
SGD의 파라미터 변경 폭이 불안정한 문제를 해결하기 위해 학습 속도와 운동량을 조정하는 옵티마이저(optimizer)를 적용해 볼 수 있음  
• (예) SGD(기본형), Momentum, AdaGrad, RMSProp, Adam, NAdam(New Adam)   
옵티마이저의 선택 그래프 중요 시험     

#### 옵티마이저로서의 SGD(Stochastic Gradient Descent, 확률적 경사 하강)   
단순히 기울기(gradient)를 이용해 가중치를 갱신하는 방법(기초)  
기울기 방향으로 일정하게 이동하는 가장 기본적인 방식  

#### 아다그라드(AdaGrad, Adaptive(적응적) gradient)  
• 가중치의 업데이트 횟수에 따라 학습률을 조정하는 방법   
• 많이 변화하지 않는 가중치들(많이 학습한)의 학습률은 크게 하고, 많이 변화하는 가중치들(적게 학습한)의 학습률은 작게 함  
• 즉, 많이 변화한 가중치는 최적 값에 근접했을 것이라 가정하고, 적게 이동하면서 세밀하게 값을 조정함  
• 그리고 적게 변화한 가중치들은 학습률을 크게 하여 빠르게 오차를 줄이고자 함  
• 처음엔 똑똑하지만, 나중엔 너무 느려짐  

G(i): 지금까지의 기울기 제곱의 누적합 -> 학습횟수 ^ -> G(i) ^   
시간이 지나면서 계속 기울기의 제곱을 누적하므로 G(i) 값이 점점 커지게 됨  
그러면 결국 분모가 너무 커져 학습률이 0에 가까워지고, 학습이 멈춰버리는 문제가 발생함  
-> 그런 단점을 보완한 AdaDelta를 사용할 수 있음  

#### 아다델타(Adadelta, Adaptive delta)  
• AdaGrad에서 G 값이 커짐에 따라 학습이 멈추는 문제를 해결하기 위해 등장한 방법  
• 과거 모든 기울기를 누적하는 대신, 최근 기울기들의 평균만 반영함(이동평균)  
• AdaGrad의 수식에서 학습률(η) 부분이 있었지만, 그 부분을 D 함수로 변환했기 때문에 학습률을 따로 정하지 않아도 됨   

#### 알엠에스프롭(RMSProp, Root Mean Square Propagation)  
• AdaGrad의 G(i) 값이 무한히 커지는 것을 방지하고자 제안된 방법  
• AdaGrad에서 학습이 안 되는 문제를 해결하기 위해 G 함수에서 γ(감마)만 추가하였음  
• 즉, G 값이 너무 크면 학습률이 작아져 학습이 안 될 수 있으므로 사용자가 γ값을 이용하여 G 값을 조절할 수 있음  
• 지수 가중 이동 평균을 이용하여 최근 데이터에 더 많은 가중치를 주는 경향이 있음  
γ값은 감쇠율, 과거 정보를 얼마나 유지할지 결정하는 값임   
γ값을 직접 설정해야 하므로, 최적 학습률을 수동으로 정해야 한다는 단점이 있음   
γ값(감마) = 0.99 -> 과거 ^  
γ값 = 0.8 -> 최근 ^  

#### 모멘텀(Momentum)
• 관성을 준 SGD   
• 이전의 이동 방향을 기억해서 부드럽게 이동함   
• (예) 이전 기울기의 0.9배를 다음 업데이트시에 더함.(단순 배수로 곱하는 것은 아님)    
• 요동치는 것을 줄이고, 빠른 방향으로 더 안정적으로 내려가는 효과가 있음    
• 즉, 가중치를 수정하기 전에 이전 수정 방향(+, -)을 참조하여 같은 방향으로 일정한 비율만 수정하는 방법    
• 지그재그 현상(수정이 양의 방향과 음의 방향으로 번갈아 일어나는 현상)이 줄어들고, 이전의 이동 값을 고려하여 일정 비율만큼 다음 값을 결정하므로 관성 효과를 얻을 수 있는 장점   
• 단점은 멈추어야 할 시점에도 관성에 의해 훨씬 멀리 갈 수 있다는 것임    
  
#### 네스테로프 모멘텀(Nesterov Accelerated Gradient, NAG)  
• 모멘텀: 모멘텀 값과 기울기 값이 더해져 최종 기울기 값을 계산함   
• NAG: 모멘텀 값이 적용된 지점에서 기울기 값을 계산함  
• 모멘텀 방법은 멈추어야 할 시점에서도 관성에 의해 훨씬 멀리 갈 수 있는 단점이 있음  
• 네스테로프 방법은 모멘텀 방식으로 일부 이동한 후 그 지점에서 기울기를 다시 계산하여 결정하기 때문에 모멘텀 방법의 단점을 극복할 수 있음  
• 모멘텀 방법의 이점인 빠른 이동 속도는 그대로 가져가면서 멈추어야 할 적절한 시점에서 제동을 거는 데 훨씬 용이함  
SGD() 파라미터로 nesterov = True 로 지정해서 사용  

내 질문: 그럼 예전 꺼는 안 쓰나요? -> 하다보면 그렇게 되지 않는다. 일반적으로 최신 것부터 선택해서 사용하지만 다양하게 시도한다.   

#### 아담(Adam, Adaptive Moment Estimation)
• 모멘텀처럼 이전 기울기 방향도 참고하고, RMSProp처럼 기울기의 크기 변화도 자동으로 조절해 빠르고 안정적으로 학습하는 옵티마이저  
• 알엠에스프롭 특징인 기울기의 제곱을 지수 평균한 값과 모멘텀 특징인 v(i)를 수식에 활용  
• 즉, 알엠에스프롭의 G 함수와 모멘텀의 v(i)를 사용하여 가중치를 업데이트함  
방향을 기억하면서도 기울기 크기에 따라 학습률을 자동으로 조정하는 최적의 방법  

## 합성곱 신경망 
순전파 과정에 따라 계산된 오차 정보가 신경망의 모든 노드(출력층 → 은닉층→ 입력층)로 전송됨  
이러한 계산 과정은 복잡하고 많은 자원(CPU 혹은 GPU, 메모리)을 요구함   
이 문제를 해결하고자 하는 것이 합성곱 신경망임    
합성곱 신경망은 이미지 전체를 한 번에 계산하는 것이 아닌 이미지의 작은 부분을 계산함으로써 시간과 자원을 절약하여 이미지의 세밀한 부분까지 분석할 수 있도록 함   
합성곱 신경망은 이미지나 영상을 처리하는 데 유용함   
합성곱 층이 없었다면,  
예를 들어 3×3 흑백(그레이스케일) 이미지가 있다고 가정해 보자  
이미지 분석은 다음 왼쪽 그림과 같은 3×3 배열을 오른쪽 그림과 같이 펼쳐서(flattening, 평탄화) 각 픽셀에 가중치를 곱하여 은닉층으로 전달하게 됨  
그림에서 보이는 것처럼 이미지를 펼쳐서 분석하면 데이터의 공간적 구조를 무시하게 되는데, 이것을 방지하려고 도입된 것이 합성곱층임  
합성곱 신경망(Convolutional Neural Network, CNN)은 음성 인식이나 이미지/영상 인식에서 주로 사용되는 신경망  
컬러 이미지 같은 다차원 배열 처리에 특화되어 있으며, 다음과 같이 5개의 계층으로 구성됨  
1. 입력층  
2. 합성곱층  
3. 풀링층  
4. 완전연결층  
5. 출력층  

합성곱 신경망은 합성곱층과 풀링층을 거치면서 입력 이미지의 주요 특성 벡터(feature vector)를 추출함  
그 후 추출된 주요 특성 벡터들은 완전연결층을 거치면서 1차원 벡터로 변환  
마지막으로 출력층에서 활성화 함수인 소프트맥스(softmax) 함수를 사용하여 최종 결과가 출력  

#### 입력층
입력층(input layer)은 입력 이미지 데이터가 최초로 거치게 되는 계층  
이미지는 단순 1차원의 데이터가 아닌 높이(height), 너비(width), 채널(channel)의 값을 갖는 3차원 데이터  
이때 채널은 이미지가 그레이스케일(gray scale)이면 1 값을 가지며, 컬러(RGB)면 3 값을 갖음  
예를들어 다음 그림과 같은 형태는 높이 4, 너비 4, 채널은 RGB를 갖고 있으므로, 이미지 형태 (shape)는 (4, 4, 3)으로 표현할 수 있음  

#### 합성곱층  
합성곱층(convolutional layer)은 입력 데이터에서 특성을 추출하는 역할을 수행  
입력 이미지가 들어왔을 때 이미지에 대한 특성을 감지하기 위해 커널(kernel)이나 필터를 사용  
커널/필터는 이미지의 모든 영역을 훑으면서 특성을 추출하게 되는데, 이렇게 추출된 결과물이 특성 맵(feature map)임  
이때 커널은 3×3, 5×5(홀수) 크기로 적용되는 것이 일반적이며, 스트라이드(stride)라는 간격에 따라 순차적으로 이동함  
  
컬러 이미지의 합성곱을 알아보겠음  
앞서 다룬 그레이스케일 이미지와 구분되는 특징은 첫째, 필터 채널이 3이라는 것과 둘째, RGB 각각에 서로 다른 가중치로 합성곱을 적용한 후 결과를 더 해 준다는 것  
그 외 스트라이드 및 연산하는 방법은 동일함  
이때 필터 채널이 3이라고 해서 필터 개수도 세 개라고 오해하기 쉬운데, 실제로는 필터 개수가 한 개라는 점에 주의해야 함  

#### 풀링층
풀링층(pooling layer)은 합성곱층과 유사하게 특성 맵의 차원을 다운 샘플링하여 연산량을 감소시키고, 주요한 특성 벡터를 추출하여 학습을 효과적으로 할 수 있게 함  
다운 샘플링은 다음 그림과 같이 이미지를 축소하는 것  

주요 풀링 연산들
- 최대 풀링(max pooling): 대상 영역에서 최댓값을 추출
- 평균 풀링(average pooling): 대상 영역에서 평균을 반환
- 최소 풀링, 전역 평균 풀링, 전역 최대 풀링
대부분의 합성곱 신경망에서는 최대 풀링이 사용되는데, 평균 풀링은 각 커널 값을 평균화 시켜 중요한 가중치를 갖는 값의 특성이 희미해질 수 있기 때문임   
최대 풀링과 평균 풀링의 계산 과정은 다르지만 사용하는 파라미터는 동일함  
입력 데이터: W1×H1×D1  
하이퍼파라미터  
필터 크기: F  
스트라이드: S  
출력 데이터  
W2 = (W1-F)/S+1   
H2 = (H1-F)/S+1  
D2 = D1  
  
#### 완전연결층
합성곱층과 풀링층을 거치면서 차원이 축소된 특성 맵은 최종적으로 완전연결층(fully connected layer)으로 전달  
이 과정에서 이미지는 3차원 벡터에서 1차원 벡터로 펼쳐지게(flatten) 됨  
#### 출력층
출력층(output layer)에서는 소프트맥스 활성화 함수가 사용되는데, 입력받은 값을 0~1 사이의 값으로 출력
마지막 출력층의 소프트맥스 함수를 사용하여 이미지가 각 레이블(label)에 속할 확률 값이 출력되며, 이때 가장 높은 확률 값을 갖는 레이블이 최종 값으로 선정  

### 1D, 2D, 3D 합성곱  
#### 1D 합성곱  
1D 합성곱은 필터가 시간을 축으로 좌우로만 이동할 수 있는 합성곱(시계열 데이터, 주식)  
그래프 곡선을 완화할 때 많이 사용   

#### 2D 합성곱  
2D 합성곱은 필터가 다음 그림과 같이 방향 두 개로 움직이는 형태  

#### 3D 합성곱
3D 합성곱은 필터가 움직이는 방향이 세 개 있음  
출력은 3D 형태  

#### 3D 입력을 갖는 2D 합성곱
입력이 (224×224×3, 112×112×32)와 같은 3D 형태임에도 출력 형태가 3D가 아닌 2D 행렬을 취하는 것이 ‘3D 입력을 갖는 2D 합성곱’  
즉, 입력(W, H, L)에 필터(k, k, L)를 적용하면 출력은 (W, H)가 됨  
이때 필터는 두 방향으로 움직이며 출력 형태는 2D 행렬이 됨  
3D 입력을 갖는 2D 합성곱의 대표적 사례로는 LeNet-5와 VGG가 있음  

#### 1×1 합성곱
1×1 합성곱은 3D 형태로 입력   
즉, 입력(W, H, L)에 필터(1, 1, L)를 적용하면 출력은 (W, H)가 됨  
1×1 합성곱에서 **채널 개수를 조정**해서 연산량이 감소되는 효과가 있으며, 대표적 사례로는 GoogLeNet이 있음   

#### (실습) 합성곱 신경망
fashion_mnist 데이터셋을 사용하여 합성곱 신경망을 직접 구현해 보자  
최대 밝기값(255)으로 나누어 정규화 (학습 안정화, 속도 향상)  
 다수의 클래스를 사용하기 때문에'sparse_categorical_crossentropy' 손실 함수를 사용  

padding: 경계 처리 방법
- valid: 유효한 영역만 출력되므로 출력 이미지 크기는 입력 이미지 크기보다 작음 (26 X 26 X 32)  
- same: 출력 이미지 크기가 입력 이미지 크기와 동일함(28 X 28 X 1)  

## 전이학습
일반적으로 합성곱 신경망 기반의 딥러닝 모델을 제대로 훈련시키려면 많은 양의 데이터가 필요함  
큰 데이터셋을 얻는 것은 쉽지 않음
큰 데이터셋을 확보하려면 많은 돈과 시간이 필요하기 때문임
이러한 현실적인 어려움을 해결한 것이 전이 학습(transfer learning)  
전이 학습이란 이미지넷(ImageNet)처럼 아주 큰 데이터셋을 써서 훈련된 모델의 가중치를 가져와  
우리가 해결하려는 과제에 맞게 보정해서 사용하는 것을 의미    
이때 아주 큰 데이터셋을 사용하여 훈련된 모델을 사전 훈련된 모델(네트워크)이라고 함  
결과적으로 비교적 적은 수의 데이터를 가지고도 우리가 원하는 과제를 해결할 수 있음  
 
특성 추출(feature extractor)은 ImageNet 데이터셋으로 사전 훈련된 모델을 가져온 후 마지막에 완전연결층 부분만 새로 만듦  
- 즉, 학습할 때는 마지막 완전연결층(이미지의 카테고리를 결정하는 부분)만 학습하고 나머지 계층들은 학습되지 않도록 함  
- 특성 추출은 이미지 분류를 위해 두 부분으로 구성  
합성곱층: 합성곱층과 풀링층으로 구성  
데이터 분류기(완전연결층): 추출된 특성을 입력받아 최종적으로 이미지에 대한 클래스를 분류하는 부분  


사전 훈련된 네트워크의 합성곱층(가중치 고정)에 새로운 데이터를 통과시키고, 그 출력을 데이터 분류기에서 훈련시킴  
• 사용 가능한 이미지 분류 모델들  
Xception  
Inception V3  
ResNet50  
VGG16   
VGG19  
MobileNet  

## 7주차 설명 가능한 CNN
설명 가능한 CNN(explainable CNN)은 딥러닝 처리 결과를 사람이 이해할 수 있는 방식으
로 제시하는 기술
• CNN은 블랙박스와 같아 내부에서 어떻게 동작하는지 설명하기 어려움
• CNN으로 얻은 결과는 신뢰하기 어려운데, 이를 해결하려면 CNN 처리 과정을 시각화해야
할 필요성이 있음
설명 가능한 CNN
• CNN을 구성하는 각 중간 계층부터 최종 분류까지 입력된 이미지에서 특성이 어떻게 추출되고 학
습하는지를 시각적으로 설명할 수 있어야 결과에 대한 신뢰성을 얻을 수 있음
• CNN의 시각화 방법에는 필터에 대한 시각화와 특성 맵에 대한 시각화가 있음
• 우리는 특성 맵에 대한 시각화로 실습을 진행할 예정
#### 실습 설명 가능한 CNN
• 특성 맵(feature map)(혹은 활성화 맵)은 입력 이미지 또는 다른 특성 맵처럼 필터를 입력에 적용한 결과
• 특정 입력 이미지에 대한 특성 맵을 시각화한다는 의미는 특성 맵에서 입력 특성을 감지하는 방법을 이해할 수 있도록 돕는 것

• 이제 Sequential API를 이용하여 모델을 만들어 보자
• 모델은 합성곱층과 최대 풀링층 쌍을 네개 쌓고 완전연결층을 순차적으로 쌓음

• 특성 맵의 시각화에 대해 살펴볼 예정이므로, 특성 맵을 정의해야 함
• 특성 맵은 합성곱층을 입력 이미지와 필터를 연산하여 얻은 결과
• 합성곱층에서 입력과 출력을 확인한다면 특성 맵에 대한 시각화가 가능할 것

• 불러온 이미지를 전처리한 후 특성 맵을 확인

입력층과 가까운 계층으로 입력 이미지의 형태가 많이 유지되고 있음
• 두 번째 계층에 대한 특성 맵을 살펴보자

아직까지는 첫 번째 계층과 큰 차이가 없어 보임  
여전히 고양이 형태는 유지하고 있음  
• 여섯 번째 계층에서 특성 맵 결과를 살펴보자  
  
이제 원래 입력 이미지의 형태는 전혀 찾아볼 수 없음  
즉, 출력층에 가까울수록 원래 형태는 찾아볼 수 없고, 이미지 특징들만 전달되는 것을 확인할 수 있음  

### 그래프 합성곱 네트워크(graph convolutional network)  
그래프 합성곱 네트워크(graph convolutional network)는 그래프 데이터를 위한 신경망   
• 그래프는 방향성이 있거나(directed) 없는(undirected) 에지로 연결된 노드(nodes=verticals)의 집합  
• 여기에서 노드와 에지는 일반적으로 풀고자 하는 문제에 대한 전문가 지식이나 직관 등으로 구성
• 그래프 신경망(Graph Neural Network, GNN)은 입력 데이터의 구조가 그래프 형태인 신경망
1단계. 인접 행렬(adjacency matrix)
네트워크가 있을 때 노드 n개를 n×n 행렬(matrix)로 표현
즉, 인접 행렬 과정은 컴퓨터가 이해하기 쉽게 그래프로 표현하는 과정이라고 할 수 있음
그래프 신경망
2단계. 특성 행렬(feature matrix)
특성 행렬은 각 노드가 어떤 속성을 가지고 있는지를 표현하는 행렬
즉, 그래프의 각 노드가 가진 특징값을 정리한 표 -> 그래프 구조에 포함된 개체들
의 특징 정보를 컴퓨터가 처리할 수 있는 형태로 정리하게 됨
• 즉, 특성 행렬 과정을 거쳐 그래프 특성(graph feature)이 추출
  
• GCN(Graph Convolutional Network)은 CNN의 “합성곱” 개념을그래프 데이터(인접행렬 + 특성행렬) 에 적용하여,노드들이 이웃으로부터 정보를 전달받고 새로운 특징을 학습하는 신경망  
  
• 그래프 합성곱층(Graph Convolutional Layer)    
: 그래프의 각 노드가 이웃 노드로부터 정보를 모아 새로운 특징을 만드는 층    
: 그래프의 전체 특징은 아직 없으며, 각 노드별 특징들만 존재함    
ResNet  
• 리드아웃(Readout)    
: 여러 노드을의 정보를 하나로 요약하는 과정   
즉, 그래프 전체를 대표하는 하나의 벡터를 생성함   
: 그래프 전체의 특징을 알아냄   
dropout 과 비슷  
• GCN은 다음과 같은 곳에서 활용됨    
SNS에서 관계 네트워크    
학술 연구에서 인용 네트워크   
분자 구조 분석   
3D Mesh   
  
## 딥러닝과 합성곱 신경망  
### 이미지 분류  
#### LeNet-5
LeNet-5는 합성곱 신경망이라는 개념을 최초로 **얀 르쿤(Yann LeCun)** 이 개발한 구조
• 1995년 얀 르쿤 등이 수표에 쓴 손글씨 숫자를 인식하는 딥러닝 구조 LeNet-5를 발표 했는데, 그것이 현재 CNN의 초석이 되었음
• LeNet-5는 합성곱(convolutional)과 다운 샘플링(sub-sampling)(혹은 풀링)을 반복적으 로 거치면서 마지막에 완전연결층에서 분류를 수행
LeNet5:                             CNN  
활성화 함수 tanh, sigmoid          ReLu, LeakyReLu 등
파라미터 수 적음                   수백 만개 ~ 수억 개
정규화 최적화 X                    Batch Normalizeon, Dropout, Adam.. 등 적용  
활용원리 제한적                    많은 영역으로 확장  

## 09주차 AlexNet
• AlexNet은 ImageNet 영상 데이터베이스를 기반으로 한 화상 인식 대회 ‘ILSVRC
2012’에서 우승한 CNN 구조
• CNN은 그림과 같이 3차원 구조를 갖는다는 것을 이해해야 함(이미지 = 너비, 높
이, 깊이가 있는 3차원 데이터)
• 보통 색상이 많은 이미지는 R/G/B 성분 세 개를 갖기 때문에 시작이 3이지만, 합
성곱을 거치면서 특성 맵이 만들어지고 이것에 따라 중간 영상의 깊이가 달라짐

AlexNet은 합성곱층 총 다섯 개와 완전연결층 세 개로 구성되어 있으며, 맨 마지막
완전연결층은 카테고리 1000개로 분류하기 위해 소프트맥스 활성화 함수를 사용하
고 있음
• 전체적으로 보면 GPU 두 개를 기반으로 한 병렬 구조인 점을 제외하면 LeNet-5와
크게 다르지 않음
• GPU 두 개를 사용하면서 연산 속도가 빨라졌다는 것은 그 당시 획기적인 기술

|계층 유형|특성 맵| 크기| 커널 크기| 스트라이드| 활성화 함수|
|---|---|---|---|---|---|
|이미지|1|227X227|-|-|-|
|합성곱층 conv1| 96| 55x55| 11x11| 4| 렐루 55X55X96|
|최대 풀링층|96|27X27|3X3|2|-|
|합성곱층 CONV2| 256| 27X27|3X3|2| ReLU 27X27X256|
|최대 풀링층|256|13X13|3X3|2|-|
|합성곱층|384|13x13|3x3|1|렐루(ReLU)|    
  
네트워크에는 학습 가능한 변수가 총 6600만 개 있음
네트워크에 대한 입력은 227×227×3 크기의 RGB 이미지이며, 각 클래스(혹은 카테고리)에 해당하는 1000×1 확률 벡터를 출력
AlexNet의 첫 번째 합성곱층 커널의 크기는 11×11×3이며, 스트라이드를 4로 적용하고 특성 맵을 96개 생성하여 55×55×96 크기로 출력함
첫 번째 계층을 거치면서 GPU-1에서는 주로 컬러와 상관없는 정보를 추출하기 위한 커널이 학습되고, GPU-2에서는 주로 컬러와 관련된 정보를 추출하기 위한 커널이 학습

### 실습 
가중치 초기화 방법으로 kernel_initializer 파라미터를 사용하였음  
• 가중치 초기화 방법 중 자주 사용되는 몇 가지  
• 확률 분포 기반의 가중치 초기화  
• 분산 조정 기반의 초기화 - LeCun 초기화, Xavier 초기화, He 초기화  
확률 분포 기반의 가중치 초기화   
• 확률 분포 기반의 초기화는 특정한 확률 분포에 기반하여 랜덤한(임의의) 값을 추출하여 가중치를 초기화  
• 이때 균일 분포(uniform distribution)와 정규 분포(normal distribution)가 사용  
- 완전 랜덤으로 진행했을 때는 기울기 폭발 혹은 기울기 소실 문제가 생길 수 있음.  
• 각각의 확률 분포 그래프는 다음 그림과 같음    
• 균일 분포는 최솟값과 최댓값 사이의 값들이 동일한 확률로 추출되는 분포   
• -0.05에서 0.05 사이의 값을 동일한 확률로 추출하도록 설정되어 있음  
• 정규 분포는 종 모양의 분포를 갖음  
• 평균에 가까운 값일수록 더 높은 확률로 추출됨  
• 평균이 0, 표준편차가 0.05인 정규 분포에서 값을 추출하도록 설정되어 있음  
• 단점: 층이 깊어지면서 분산값이 폭발하거나 분산값이 소멸하는 현상이 발생함  
• 대안: 분산 기반 초기화(다음 페이지)  
확률 분포 기반의 가중치 초기화

분산 조정 기반의 초기화
(**idea**: "입력과 출력의 분산을 일정하게 유지하려면, 어떻게 해야할까? ")
 
• 분산 조정 기반의 초기화란 확률 분포를 기반으로 추출한 값으로 가중치를 초기화하되, 이 확률 분포의 분산을 가중치별로 동적으로 조절해 주는 것   
• 분산을 조절할 때는 해당 가중치에 입력으로 들어오는 텐서의 차원(fan in)과 결괏값으로 출력하는 텐서의 차원(fan out)이 사용  
• 다음은 케라스에서 사용되는 분산 조정 기반의 가중치 초기화 방식   

##### LeCun 초기화 방식(1998): 이 방식에는 lecun_uniform과 lecun_normal이 있음    
입력(fan in) 입력 노드가 많을 수록 가중치를 작게 만들어서 가중치의 폭발(폭주)를 방지함.    
이 방식은 입력 값의 크기가 커질수록 초기화 값의 분산을 작게 만듦    
그 결과로 0에 가까운 값들이 추출  

##### Xavier 초기화 방식(2010): 이 방식에는 glorot_uniform과 glorot_normal이 있음
이 방식은 fan in과 fan out을 모두 고려하여 확률 분포를 계산  
LeCun 방식에서 2를 곱한 후 fan in과 fan out을 합한 크기로 나누어 준 값으로 확률 분포를 조정함  
(fan-in: tanh, sigmoid,   fan-out: 대칭형 활성화 함수에서 입-출력의 분산이 둘 다 일정하도록 조정하는 방식)   
이 방식은 하이퍼볼릭 탄젠트를 활성화 함수로 사용하는 신경망에서 많이 사용  
렐루를 활성화 함수로 사용할 때는 잘 작동하지 않는 단점이 있음   
(절반이 0이 되는 활성화 함수)  

##### He 초기화 방식(2015): 이 방식에는 he_uniform과 he_normal이 있음  
이 방식은 Xavier 방식의 한계를 극복하려고 제안된 기법  
또한, ResNet을 학습시킬 때 이 기법을 사용하여 실제로 CNN의 깊은 신경망을 잘 학습시킬 수 있음을 보여 주었음  
(대칭이 아닌 활성화 함수에 최적(요즘 사용하는 대부분의 cnn에서 사용)  
수식을 살펴보면 Xavier 방식에서 다시 fan out을 제거  
즉, fan out보다 **fan in에 집중**한 가중치로 이해하면 됨   

**fan in과 fan out** 
• fan in이란 해당 계층에 들어오는 입력 텐서(input tensor)에 대한 차원의 크기  
• fan out은 해당 계층이 출력하는 출력 텐서(output tensor)의 크기  
• 예를 들어 1000×200 크기의 완전연결층에서 fan in은 1000, fan out은 200이 됨  
• CNN과 RNN은 좀 더 복잡해짐  
  
data_format은 입력에 대한 형식을 지정할 때 사용  
• 입력 형식을 설정하는 파라미터로 'channels_last'와 'channels_first'가 있으며, 기본 값은 'channels_last‘   
• 'channels_last'를 사용하면 입력 데이터 텐서의 형식이 (배치 크기, 높이, 너비, 채널 개수)가 됨   
• 'channels_first'를 사용하면 입력 데이터 텐서의 형식이 (배치 크기, 채널 개수, 높이, 너비)가 됨   

• AlexNet은 파라미터를 매우 많이 사용하는데, 이때 충분한 데이터가 없으면 과적합이 발생함  
• 예제는 충분한 규모의 데이터가 아니므로 작은 데이터셋을 사용하여 강력한 성능을 낼 수 있는 전처리가 필요함  

### VGGNet  
제작한 팀의 이름을 본 땀  
VGGNet은 합성곱층의 파라미터 개수를 줄이고 훈련 시간을 개선하려 발명됨  
• 네트워크 계층의 총 개수에 따라 여러 유형의 VGGNet(VGG16, VGG19 등)이 있음  
• 여기에서 주목할 점은 모든 합성곱 커널의 크기는 3×3, 최대 풀링 커널의 크기는 2×2이며, 스트라이드는 2임  

학습가능한 층의 수: vgg16, vgg19 11, 12 등  
합성곱 층, 완전연결층의 개수, (최대풀링층,소프트맥스 제외)  

|계층 유형|특성 맵| 크기| 커널 크기| 스트라이드| 활성화 함수|
|---|---|---|---|---|---|
|이미지|1|224X224|-|-|-|
|합성곱층| 64| 224X224 | 3x3| 1| 렐루|
|합성곱층| 64| 224X224 | 3x3| 1| 렐루|
|최대 풀링층|64|112X112|2X2|2|-|
|합성곱층|128|112X112|3X3|1| ReLU|
|합성곱층|128|112X112|3X3|1| ReLU|
|최대 풀링층|256|56X56|2X2|2|-|
|합성곱층|256|56x56|3x3|1|렐루(ReLU)|    
|합성곱층|256|56x56|3x3|1|렐루(ReLU)|    

  
### GoogLeNet(Inception)  
GoogLeNet은 주어진 하드웨어 자원(gpu)을 최대한 효율적으로 이용하면서 학습 능력은 극대화할 수 있는 깊고 넓은 신경망임  
• 깊고 넓은 신경망을 위해 GoogLeNet은 인셉션(Inception) 모듈을 추가  
• 인셉션 모듈에서는 특징을 효율적으로 추출하기 위해 1×1, 3×3, 5×5의 합성곱 연산을 각각 수행함  
• 3×3 최대 풀링은 입력과 출력의 높이와 너비가 같아야 하므로 풀링 연산에서는 드물게 패딩을 추가해야 함  
• 결과적으로 GoogLeNet에 적용된 해결 방법은 희소 연결(sparse connectivity)  
GAP (global Average Pooling)   
  
CNN은 합성곱, 풀링, 완전연결층들이 서로 밀집(dense)(정교하고 빽빽하게)하게 연결되어 있음  
• 빽빽하게 연결된 신경망 대신 관련성(correlation)이 높은 노드끼리만 연결하는 방법을 희소 연결이라고 함    
• 이것으로 연산량이 적어지며 과적합도 해결할 수 있음  
딥러닝을 이용하여 ImageNet과 같은 대회에 참여하거나 서비스를 제공하려면 대용량 데이터를 학습해야 함  
• 심층 신경망의 아키텍처에서 계층이 넓고(뉴런이 많고) 깊으면(계층이 많으면) 인식  
률은 좋아지지만, 과적합이나 기울기 소멸 문제(vanishing gradient problem)를 비롯한 학습 시간 지연과 연산 속도 등의 문제가 있음 
• 특히 합성곱 신경망에서 이러한 문제들이 자주 나타나는데, GoogLeNet(혹은 인셉션(Inception)이라고도 불림)으로 이러한 문제를 해결할 수 있음  
GoogleNet의 인셉션 모듈 4갈래   
**병렬, 동시 연산**  
필터연결 (ex. 28 X 28 X (64 + 128 + 32 + 32))   
1. 1×1 합성곱(비선형성)(ex.28X28X64)   
2. 1×1 합성곱(채널 수 조절, 차원 축소(연산량 축소) + 3×3 합성곱(ex.28X28X128)   
padding 적용(크기가 달라지지 않음)  
3. 1×1 합성곱(채널 수 조절, 차원 축소(연산량 축소) + 5×5 합성곱(padding =2, ex.28X28X32)   
padding 적용(크기가 달라지지 않음)  
4. 3×3 최대 풀링(maxpooling)(stride=1 padding = 1, 차원축소 X) + 1×1 합성곱(convolutional)(차원 복구. 특징 보강)(ex.28X28X32)    
  
이 4가지가 모두 병렬, 동시 진행    
인셉션 모듈의 장점   
- 멀티 스케일 -> 디테일과 문맥을 동시에  
- 차원 축소 -> 연산량 감소, 메모리 필요 감소   
- 모듈화 가능 -> inception 블록 자체를 쌓을 수 있음  

딥러닝을 이용하여 ImageNet과 같은 대회에 참여하거나 서비스를 제공하려면 대용량 데이터를 학습해야 함  
심층 신경망의 아키텍처에서 계층이 넓고(뉴런이 많고) 깊으면(계층이 많으면) 인식률은 좋아지지만, 과적합이나 기울기 소멸 문제(vanishing gradient problem)를 비롯한 학습 시간 지연과 연산 속도 등의 문제가 있음  
특히 합성곱 신경망에서 이러한 문제들이 자주 나타나는데, GoogLeNet(혹은 인셉션(Inception)이라고도 불림)으로 이러한 문제를 해결할 수 있음   

### ResNet  
ResNet은 마이크로소프트에서 개발한 알고리즘으로 “Deep Residual(잔차) Learning for Image Recognition”이라는 논문에서 발표  
ResNet 핵심은 깊어진 신경망을 효과적으로 학습하기 위한 방법으로 레지듀얼(residual) 개념을 고안한 것  
일반적으로 신경망 깊이가 깊어질수록 딥러닝 성능은 좋아질 것 같지만, 실상은 그렇지 않음  
“Deep Residual Learning for Image Recognition” 논문에 따르면, 신경망은 깊이가 깊어질수록 성능이 좋아지다가 일정한 단계에 다다르면 오히려 성능이 나빠짐   
(교과서 그래프) 네트워크 56층이 20층보다 더 나쁜 성능을 보임을 알 수 있음   
즉, 네트워크 깊이가 깊다고 해서 무조건 성능이 좋아지지는 않음   
ResNet은 바로 이러한 문제를 해결하기 위해 레지듀얼 블록(residual block)을 도입했음  
레지듀얼 블록은 기울기가 잘 전파될 수 있도록 일종의 숏컷(shortcut, skip connection)을 만들어 줌  
이러한 개념이 필요한 이유는 2014년에 공개된 GoogLeNet은 층이 총 22개로 구성된 것에 비해 ResNet은 층이 총 152개로 구성되어 기울기 소멸 문제가 발생할 수 있기 때문임  
다음 그림과 같이 숏컷을 두어 기울기 소멸 문제를 방지했음    
기존 신경망은 입력 값 x를 출력 값 y로 매핑하는 함수 H(x)를 얻는 것이 목적  
ResNet은 F(x)+x를 최소화하는 것을 목적으로 함  
여기에서 F(x)는 레지듀얼 함수라고 하며, 두 개의 합성곱층 사이에 위치  
또한, 출력(H(x))과 입력 x에 대한 차(F(x)=H(x)-x)로 표현할 수 있음  
x는 현시점에서 변할 수 없는 값이므로 F(x)를 0에 가깝게 만드는 것이 목적  
F(x)가 0이 되면 출력과 입력 모두 x로 같아지게 됨  
즉, F(x)=H(x)-x이므로 F(x)를 최소로 한다는 것은 H(x)-x를 최소로 한다는 것과 의미가 동일함  
• 여기에서 H(x)-x를 레지듀얼이라고 하며, 이때 레지듀얼 이름을 따서 ResNet(Residual Network)으로 부르게 되었음  
  
• 이 과정을 정리하면 다음과 같음  
1. 입력(x)과 레이블(y) 관계를 설명하는 함수 H(x)=x가 되도록 학습시킴  
2. F(x)가 0이 되도록 학습시킴  
3. 결국 F(x)+x=H(x)=x가 되도록 학습시키면 F(x)+x의 미분 값은 F′(x)+1로 최소 1 이상의 값이 도출됨  
4. 모든 계층에서 기울기가 F′(x)+1이므로 (오차가 0에 가깝게 수렴하여 발생하는) 기울기 소멸 문제가 해결됨  
• ResNet 구조는 다음 그림과 같이 숏컷으로 만들어진 블록인 아이덴티티 블록 (identity block)과 합성곱층으로 구성된 합성곱 블록(convolutional block)으로 구성  

합성곱 블록 + 아이덴티티 블록(그대로 전달) 이걸 묶어서 여러번 반복  

단순히 아이덴티티 블록은 이전까지 설명했듯이 네트워크의 F(x)에 x를 그대로 더하는 것이고, 합성곱 블록은 x가 1×1 합성곱층을 거친 후 F(x)에 더해 주는 것  
ResNet은 이 두 블록을 같이 쌓아서 구성함  

ResNet은 기본적으로 VGG19 구조를 뼈대로 하며, 거기에 합성곱층들을 추가해서 깊게 만든 후 숏컷들을 추가하는 것이 사실상 전부라고 생각하면 됨  
#### (실습)  
#### BatchNormalization
BatchNormalization은 데이터의 평균을 0으로, 표준편차를 1로 분포시키는 것  
각 계층에서 입력 데이터의 분포는 앞 계층에서 업데이트된 가중치에 따라 변함  
즉, 각 계층마다 변화되는 분포는 학습 속도를 늦출 뿐만 아니라 학습도 어렵게 함  
각 계층의 입력에 대한 분산을 평균 0, 표준편차 1로 분포시키는 것  

컴퓨터 비전 분야에서 객체를 분류하는 방법에서 중요한 것은 데이터이지 모델이 아님
신경망(혹은 네트워크)은 이미 구현된 모델을 재사용할 수 있는 것이 많기에 우리는 단지 누군가가 만들어 놓은 신경망을 가져다 쓰기만 하면 됨  
중요한 점은 내가 가진 데이터에 가장 적합한 모델을 선택하는 것  
또한, 앞서 배운 전이 학습을 사용하여 약간의 튜닝만 진행하면 됨  


## 10주차 CNN2

### 객체 인식
객체 인식(object detection)은 이미지나 영상 내에 있는 객체를 식별하는 컴퓨터 비전 기술  
즉, 객체 인식이란 이미지나 영상 내에 있는 여러 객체에 대해 각 객체가 무엇인지를 분류하는 문제와 그 객체의 위치가 어디인지 박스(bounding box)로 나타내는 위치 검출(localization) 문제를 다루는 분야
객체 인식은 다음과 같이 표현할 수 있음
객체 인식을 위한 신경망
딥러닝을 이용한 객체 인식 알고리즘은 크게 1단계 객체 인식(1-stage detector)과 2단계 객체 인식(2-stage detector)으로 나눌 수 있음
1단계 객체 인식 vs 2단계 객체 인식 흐름도
2단계 R-CNN (두번 통과)  
2013 R-CNN 2014 2015 Fast R-CNN 
1단계 YOLO SSD Focal LOSS RefineDet 
1단계 객체 인식은 이 두 문제(분류와 위치 검출)를 동시에 행하는 방법이고, 2단계 객체 인식은 이 두 문제를 순차적으로 행하는 방법    
1단계 객체 인식은 비교적 빠르지만 정확도가 낮고, 2단계 객체 인식은 비교적 느리지만 정확도가 높음   
2단계 객체 인식은 CNN을 처음으로 적용시킨 R-CNN 계열이 대표적이며, 1단계 객체 인식에는 YOLO(You Only Look Once) 계열과 SSD 계열 등이 포함   
참고로 객체 인식은 자율 주행 자동차, CCTV, 무인 점포 등 많은 곳에서 활용   

#### YOLO (You Only Look Once)
이미지를 모델에 한 번만 통과시켜 모든 객체를 한꺼번에 탐지함.     
이미지를 그리드(Grid) 로 나누고 (예: 7×7 → 총 49개의 영역), 각 셀은 자신의 영역 안에 중심점을 가진 객체가 있는지를 판단함.    
객체가 있다면 다음 값을 함께 예측함:   
- 객체의 좌표 (x, y, w, h)   
- 객체 존재 확률 (objectness)   
- 클래스별 확률 (class probability)   
이렇게 모든 셀의 예측 결과를 종합해 전체 객체의 위치와 종류를 결정함.  
장점: 매우 빠르고 실시간 처리에 적합함.
단점: 작은 객체나 겹친 객체를 구분하는 데 다소 약함.  

#### SSD(Single Shot MultiBox Detector)
Single Shot: 한 번의 예측으로 객체를 탐지함.  
MultiBox: 다양한 크기와 비율의 박스(anchor boxes)를 동시에 탐지함.  
SSD는 CNN의 feature map의 여러 단계(다양한 크기) 에서 서로 다른 크기와 비율의 anchor box(기준 상자) 를 미리 설정함.  
각 박스마다 다음 정보를 예측함:  
- 객체 여부 (objectness)  
- 클래스 (class)  
- 위치 보정값 (offset)  
이 과정을 통해 크기가 서로 다른 객체를 모두 잘 탐지할 수 있음.  
예시:  
- 저해상도 feature map → 큰 물체 탐지  
- 고해상도 feature map → 작은 물체 탐지  
장점: YOLO보다 **작은 물체 탐지**에 강함.  
실시간 속도를 유지하면서도 정확도가 높고, 여러 단계의 feature map을 활용하여 다양한 크기의 객체를 효과적으로 인식함.  
단점: 구조가 다소 복잡하고, anchor box 설정이 탐지 성능에 큰 영향을 줌.   

->  CNN Feature map에 다양한 앵커박스를 먼저 놓고 각 앵커박스마다 클래스의 확률 위치 보정값을 탐지 불필요한 박스를 지우고 객체를 탐지   
Anchor Box(앵커 박스)   
모양이 다른 탐지용 기준 틀 (template box)   
각기 다른 크기와 비율을 가진 여러 anchor box들을 각 셀(feature map의 위치)에 겹쳐 놓고 판단함    
모델은 학습을 통해 “이 기준 상자를 얼마나 이동·확대·축소해야 실제 객체와 일치하는가”를 학습함   
예시  
- 버스 → 가로로 긴 직사각형  
- 사람 → 세로로 긴 직사각형  
- 얼굴 → 정사각형  
- 사과 → 정사각형  
요약  
• 다양한 anchor box를 이용해 형태가 다른 물체들을 동시에 인식할 수 있음  
  
#### R-CNN(Region-based CNN, Region-with CNN)  
(idea) "전체를 다 보지 말고, 객체가 있을법한 후보 영역만 뽑아서 그 부분만 CNN으로 정밀하게 보자"   
예전의 객체 인식 알고리즘들은 슬라이딩 윈도우(sliding window) 방식, 즉 일정한 크기를 가지는 윈도우(window)를 가지고 이미지의 모든 영역을 탐색하면서 객체를 검출해 내는 방식  
알고리즘의 비효율성 때문에 많이 사용하지 않았으며, 현재는 선택적 탐색(selective search) 알고리즘을 적용한 후보 영역(region proposal)을 많이 사용  
R-CNN(Region-based CNN)은 이미지 분류를 수행하는 CNN과 이미지에서 객체가 있을 만한 영역을 제안해 주는 후보 영역 알고리즘을 결합한 알고리즘  
1. 이미지 삽입 2. 후보 영역 추출 - 압축 영역  3.CNN 특성 계산 4. 영역 분류   
비슷한 색과 공간을 가진 묶음 -> 각각 이미지를 CNN을 여러번 통과  
    
1단계. 초기 영역 생성(sub-segmentation)  
입력 이미지를 작은 조각(초기 segment)로 분할함(ex.cv super pixel...)    
색상, 질감, 밝기 등이 비슷한 픽셀끼리 묶어 기초 영역(seed region)을 만듦    
   
2단계. 작은 영역의 통합   
1단계에서 영역 여러 개로 나눈 것들을 비슷한 영역으로 통합함   
이때 탐욕(greedy) 알고리즘을 사용하여 비슷한 영역이 하나로 통합될 때까지 반복함   
   
3단계. 후보 영역 생성    
합쳐진 각 영역의 외곽선을 감싸는 사각형(Bounding Box)을 추출함    
이것이 CNN에 들어갈 후보 영역들이 됨    
   
4단계. 모양을 맞추는 워핑(Resizing)을 한 후 CNN에 입력  
Bounding Box 내에 있는 내용을 고정된 크기로 resize(잘라내기, 여백추가 등)하여 CNN(AlexNet 등)에 입력하여 객체의 종류를 파악함     
- 완전 탐색(exhaustive search): 후보가 될 만한 대상의 크기 및 비율이 모두 다른 상황을 고려하여 후보 영역을 찾는 기법  
- 분할(segmentation): 영상 데이터의 특성(색상, 모양, 무늬 등)에 따라 분할하여 후보 영역을 선정하는 기법   
- 후보 영역(바운딩 박스): 객체의 형태를 모두 포함할 수 있는 최소 크기의 박스  
- 시드(seed): 영상에서는 특정 기준점의 픽셀에서 점점 의미가 같은 영상 범위까지 픽셀을 확장해 나가면서 분할하는데, 이때 특정 기준점이 되는 픽셀  
   
장점: CNN을 객체 탐지에 적용하여 정확도가 높음   
기존의 완전탐색 방식보다 객체 인식 속도가 빠름   
단점:R-CNN은 성능이 뛰어나기는 하지만 다음과 같은 단점으로 크게 발전하지는 못했음    
1. 복잡한 학습 과정  
2. 긴 학습 시간과 대용량 저장 공간  
3. 객체 검출(object detection) 속도 문제  
이러한 문제를 해결하기 위해 Fast R-CNN이 생겼음  

#### 공간 피라미드 풀링 (Spatial Pyramid Pooling, SPP)  
기존 CNN 구조들은 고정된 크기의 완전연결층(Fully connected layer)에 맞추기 위해 입력 이미지의 크기를 고정해야 했음  
즉, 신경망에 이미지를 입력하려면 이미지를 고정된 크기로 자르거나(crop) 비율을 조정(warp)해야 했음  
이렇게 하면 물체의 일부분이 잘리거나 본래의 생김새와 달라지는 문제점이 있음  
이러한 문제를 해결하고자 공간 피라미드 풀링(spatial pyramid pooling)을 도입함   

입력 이미지의 크기에 관계없이 일단 합성곱층을 통과시키고, 완전연결층에 전달되기 전에 특성 맵들을 동일한 크기로 조절해 주는 풀링층을 적용하는 기법   
입력 이미지의 크기를 조절하지 않고 합성곱층을 통과시키기 때문에 원본 이미지의 특징이 훼손되지 않은 특성 맵을 얻을 수 있음   
r-cnn은 (resizing warping) 을 거치고 연결이지만   
“SPP 구조 흐름도 (Conv → SPP → FC)”   
공간 피라미드 풀링을 적용한 것은 R-CNN이 아닌, SPP-Net임   

#### Fast R-CNN
R-CNN은 바운딩 박스마다 CNN을 돌리고, 분류를 위한 긴 학습 시간이 문제였음   
Fast R-CNN(Fast Region-based CNN)은 R-CNN의 속도 문제를 개선하려고 RoI 풀링을 도입  
(idea) "이미지를 CNN에 한 번만 넣고, 그 결과인 feature map 위에서 여러 ROI를 처리하자"  
  
Fast R-CNN의 전체 흐름  
  
1. 입력 이미지를 CNN에 한 번만 통과시켜 feature map을 생성한다.  
2. 원본 이미지에서 Selective Search로 후보영역(ROI)을 여러 개 만든다.  
3. 각 ROI의 위치를 feature map 좌표로 변환한다.  
4. ROI가 차지하는 feature map 부분을 잘라내어 RoI Pooling을 적용한다.  
- RoI Pooling은 ROI 영역을 7×7과 같은 고정된 구획으로 나누고, 각 구획에서 Max Pooling을 수행해 ROI마다 일정 크기의 특징(예: 7×7×채널 수)을 얻는 과정이다.   
5. RoI Pooling의 출력은 완전연결층(FC Layer)에 들어가 분류와 박스 위치 보정을 동시에 수행한다.    
6. 여러 ROI에서 나온 중복 박스를 NMS(Non-Maximum Suppression)로 정리하여 최종 탐지 결과를 만든다.  
  
RoI 풀링  
RoI 풀링(RoI pooling)은 크기가 다른 특성 맵의 영역마다 스트라이드를 다르게 최대 풀링을 적용하여 결괏값 크기를 동일하게 맞추는 방법   
예를 들어 다음 그림과 같이 박스 한 개가 픽셀 한 개를 뜻하는 특성 맵이 있다고 하자  
즉, 8×8 특성 맵(❶)에서 선택적 탐색으로 뽑아냈던 7×5 후보 영역(❷)이 있으며, 이것을 2×2로 만들기 위해 스트라이드(7/2=3, 5/2=2)로 풀링 영역(❸)을 정하고 최대 풀링을 적용하면 2×2 결과(❹)를 얻을 수 있음   

RPN (RoI Pooling Network)   
Faster R-CNN은 ‘더욱 빠른’ 객체 인식을 수행하기 위한 네트워크  
기존 Fast R-CNN 속도의 걸림돌이었던 후보 영역 생성을 CNN 내부네트워크에서 진행할 수 있도록 설계  
즉, Faster R-CNN은 기존 Fast R-CNN에 후보 영역 추출 네트워크(RegionProposal Network, RPN)를 추가한 것이 핵심이라고 할 수 있음  
Faster R-CNN에서는 외부의 느린 선택적 탐색(CPU로 계산) 대신 내부의빠른 RPN(GPU로 계산)을 사용  
RPN은 다음 그림과 같이 마지막 합성곱층 다음에 위치  
그 뒤에 Fast R-CNN과 마찬가지로 RoI 풀링과 분류기(classifier), 바운딩박스 회귀(bounding-box regression)가 위치  
RPN(후보 영역 추출 네트워크)은 feature map 전체를 훑으며 후보 영역을 뽑아내는 역할을 함   
#### spp-net 
RPN이 뽑은 수천개의 바운딩 박스 중, NMS(Non Maximum Suppression)을 통해 겹치고 불필요한 부분을 제거함이후 RoI Pooling으로 고정된 크기의 특징을 뽑아내고, 완전연결층에 입력하여 클래스 분류 등을 하여 객체를 인식함   
    
RPN(후보 영역 추출 네트워크)는 이미지에 존재하는 객체들의 크기와 비율이 다양하기 때문에 고정된 N×N 크기의 입력만으로 다양한 크기와 비율의 이미지를 수용하기 어려운 단점이 있음  
이러한 단점을 보완하기 위해 여러 크기와 비율의 레퍼런스 박스(reference box) k개를 미리 정의하고 각각의 슬라이딩 윈도우 위치마다 박스 k개를 출력하도록 설계하는데, 이 방식을 앵커(anchor)라고 함  

### 이미지 분할(image segmentation)  
이미지 분할은 신경망을 훈련시켜 이미지를 픽셀 단위로 분할하는 것   
즉, 이미지를 픽셀 단위로 분할하여 이미지에 포함된 객체를 추출함  
주요 네트워크  
FCN(Fully Convolutional Network, 완전 합성곱 네트워크)  
Convolutional & Deconvolutional Network(합성곱 & 역합성곱 네트워크)  
U-Net   
PSPNet   
DeepLabv3 / DeepLabv3+  
#### FCN(완전 합성곱 네트워크)  
완전연결층의 한계는 고정된 크기의 입력만 받아들이며, 완전연결층을 거친 후에는 위치 정보가 사라진다는 것  
이러한 문제를 해결하기 위해 완전연결층을 1×1 합성곱으로 대체하는 것이 완전 합성곱 네트워크  
완전연결층을 1*1합성곱으로 대체하면 공간 정보(높이*너비)가 보존됨  
출력 형태는 h*w 크기의 feature map들  
즉, 완전 합성곱 네트워크(Fully Convolutional Network, FCN)는 이미지 분류에서 우수한 성능을 보인 CNN 기반 모델(AlexNet, VGG16, GoogLeNet)을 변형시켜 이미지 분할에 적합하도록 만든 네트워크  
기존 CNN은 완전연결층때문에 이미지 크기를 제약했어야 했다면 완전 합성곱 네트워크에서는 모든 연산이 Convolution과 Pooling으로만되어 있기 때문에, 입력이 어느 크기든 모델에 입력되어 흘러가여 feature map을 생성할 수 있음  
(참고) Conv와 Pool은 입력의 크기를 강제로 고정하고 있지 않음  
완전 합성곱 네트워크는 위치 정보가 보존된다는 장점에도 다음과 같은 단점이 있음  
- 여러 단계의 합성곱층과 풀링층을 거치면서 해상도가 낮아짐  
- 낮아진 해상도를 복원하기 위해 단순한 업샘플링 방식을 사용하기 때문에 이미지의 세부정보들을 잃어버리는 문제가 발생함. -> 이미지의 세밀한 경계 복원이 어려움  
이러한 문제를 해결하기 위해 역합성곱 네트워크를 도입한 것이 합성곱 & 역합성곱 네트워크(convolutional & deconvolutional network)   
역합성곱(Deconvolution)은 CNN의 최종 출력 결과를 원래의 입력 이미지와 같은 크기를 만들고 싶을 때 사용  
시멘틱 분할(semantic segmentation) 문제 등에 활용할 수 있으며, Deconvolution은 업샘플링 방식의 일종임  
이미지 크기를 다시 늘리면서, 동시에 확대된 곳에 디테일을 그려넣는 방식이라고 볼 수 있음.  
Deconvolution에서 사용하는 필터(커널)도 학습이 가능한 형태임.  
즉, 역합성곱 커널은 이미지의 업샘플링을 잘 하도록 학습되는 것  

CNN에서 합성곱층은 합성곱을 사용하여 특성 맵 크기를 줄임  
역합성곱은 이와 반대로 특성 맵 크기를 증가시키는 방식으로 동작  
역합성곱은 다음 방식으로 동작  
1. 각각의 픽셀 주위에 제로 패딩(zero-padding)을 추가  
2. 이렇게 패딩된 것에 합성곱 연산을 수행  

#### U-Net 
U-Net은 바이오 메디컬 이미지 분할을 위한 합성곱 신경망   
U-Net은 기존 슬라이딩 윈도우 방식의 CNN보다 속도가 빠르다는 장점이 있음  
U-Net은 트레이드오프(trade-off)에 빠지지 않는다는 특징이 있음
- 트레이드오프(trade-off) 비용과 결과의 상충관계    
일반적으로 패치 크기가 커진다면 넓은 범위의 이미지를 인식하는 데 뛰어나기 때문에 컨텍스트(context) 인식에 탁월한 반면,
지역화(Localization)에는 한계가 있었음
U-Net은 컨텍스트 인식과 지역화를 모두 잘 함  
U-Net은 FCN(Fully Convolutional Network)을 기반으로 구축되었으며, 수축 경로(contracting path)와 확장 경로(expansive path), Skip Connection으로 구성되어 있음  
Contracting Path/Downsampling Path/Encoder   
이미지에서 의미 정보를 추출하는 일반적인 CNN 구조  
해상도는 점점 낮아지고, 특징을 추출해내는 역할을 함  
Expansive Path/Upsampling Path/Decoder  
줄어든 해상도를 다시 키우면서 segmentation mask를 복원함  
해상도가 점점 올라가며, 정교한 형태로 복원됨  
즉, 정확한 지역화(Localization)를 수행함  
Skip Connection  
Encoder의 중간 과정에서 나오는 feature map을 Decoder와 같은 수준의 해상도 지점에 그대로 복사하여 붙여줌  
그래서 기존의 이미지에서 지역적인 정보를 잃지 않고 더 정교하게 segmentation 가능  
#### PSPNet  
PSPNet(Pyramid Scene Parsing Network)은 CVPR(The IEEE Conference on Computer Vision and Pattern Recognition) 2017에서 발표된 시멘틱 분할 알고리즘   
PSPNet은 이미지 전체를 큰 그림부터 작은 부분까지 다양한 크기의 시야(receptive field)로 바라보고, 그 정보를 합쳐 더 정확한 세그멘테이션(분할)을 수행하는 모델   
기존 모델은은 feature map만 보고 주변의 작은 패턴만 분석하므로, 장면 전체의 의미를 파악하는 능력이 부족하였음. 이런 한계를 극복하기 위해 피라미드 풀링 모듈(PPM)을 추가했음.   
지역화(localization)는  이미지 안에 객체 위치 정보를 출력해 주는 것으로, 주로 바운딩 박스를 많이 활용함  

Pyramid Pooling Module(PSP Module)   
핵심 아이디어: Feature map을 여러 크기로 요약(pooling)하여 큰 그림(전역 정보)부터 작은 영역(지역 정보)까지 모두 확보한 뒤, 다시 합치겠다.  
1. 이미지 출력이 서로 다른 크기가 되도록 여러 차례 풀링을 함  
-즉, 1×1, 2×2, 3×3, 6×6 크기로 풀링을 수행하는데, 이때 1×1 크기의 특성 맵은 가장 광범위한 정보를 담음   
-각각 다른 크기의 특성 맵은 각각 다른 수준에서 이미지를 바라보며 요약하는 것이라 이해하면 됨   
2. 이후 1×1 합성곱을 사용하여 채널 개수를 조정함   
3. 이후 모듈의 입력 크기에 맞게 특성 맵을 업 샘플링  
-이 과정에서 양선형 보간법(bilinear interpolation)이 사용됨  
4. 원래의 특성 맵과 1~3 과정에서 생성한 새로운 특성 맵들을 병합함  

 구조  
Input  
↓  
Backbone CNN (ResNet50/101)  
↓  
Final Feature Map (ex: 60×60)  
↓   
[Pyramid Pooling Module]  
- 1×1 pooling → upsample  
- 2×2 pooling → upsample  
- 3×3 pooling → upsample   
- 6×6 pooling → upsample   
→ 모두 concat   
↓   
Segmentation Head (Conv)   
↓  
Upsampling  
↓  
Final Segmentation Map  
  
segmentation head(conv)가 출력 채널 수를 클래스 수로 맞춰주는 층이라고 보면 됨.  
예: 사람, 도로, 자동차, 나무 -> 4개의 픽셀로 나타내고, 가장 확률이 높은 쪽으로 픽셀을 그 채널로 할당함   
예:   
첫번째 픽셀: [0.1, 0.8, 0.05, 0.05 ] -> "도로"  
5123번째 픽셀: [0.9, 0.03, 0.02, 0.05] -> "사람"  































































----
